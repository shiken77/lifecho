import os
import json
import base64
import httpx
import google.generativeai as genai # googleå®˜æ–¹çš„sdk
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Literal
from dotenv import load_dotenv
from google.cloud import texttospeech

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
app = FastAPI()

# è·¨åŸŸé…ç½®ï¼šå…è®¸å‰ç«¯ 3000 ç«¯å£è®¿é—®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- æ ¸å¿ƒé…ç½®åŒº (è¯·åœ¨ .env æ–‡ä»¶ä¸­å¡«å†™) ---
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_MODEL_ID = os.getenv("GEMINI_MODEL_ID", "gemini-flash-latest")  # é»˜è®¤ä½¿ç”¨ gemini-flash-latest
genai.configure(api_key=GEMINI_API_KEY)

# --- æ•°æ®æ¨¡å‹ ---
class Message(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    context: str = ""  # ç§å­è¯é¢˜ï¼ˆç”¨æˆ·åœ¨P1é¦–é¡µè¾“å…¥çš„"ä»Šæ—¥å‘ç”Ÿçš„äº‹æƒ…"ï¼‰
    tone: Literal["Gentle", "Normal", "Serious"]  # è¯­æ°”ï¼šåªèƒ½é€‰æ‹© Gentle, Normal, Serious ä¸‰ç§
    mentorRole: str = ""  # è§’è‰²åç§°
    turn: int = 6   # è®¾å®šè½®æ¬¡ï¼Œé»˜è®¤6è½®
    history: list[Message]
    previous_communication_raw: list[dict] = []  # ä¹‹å‰çš„å®Œæ•´ communication_rawï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºä¿ç•™æ‰€æœ‰å­—æ®µ
    audio_base64: str = ""  # ç”¨æˆ·è¯­éŸ³è¾“å…¥ï¼ˆbase64ç¼–ç ï¼Œå¯é€‰ï¼‰
    audio_mime_type: str = "audio/webm"  # éŸ³é¢‘MIMEç±»å‹

class RefineRequest(ChatRequest):
    correction_summary: str  # ç”¨æˆ·è¾“å…¥çš„ä¿®æ­£å†…å®¹

class FinalGenerationRequest(BaseModel):
    communication_raw: list[dict]  # åŸå§‹å¯¹è¯å†å²ï¼ˆcommunication_raw æ ¼å¼ï¼‰
    refined_summary_ja: str  # ç²¾ç‚¼åçš„æ‘˜è¦ï¼ˆæ—¥è¯­ï¼‰
    refined_summary_zh: str = ""  # ç²¾ç‚¼åçš„æ‘˜è¦ï¼ˆä¸­æ–‡ï¼Œå¯é€‰ï¼‰
    context: str = ""
    tone: Literal["Gentle", "Normal", "Serious"]
    mentorRole: str = ""
    
    def to_history(self) -> list[Message]:
        """
        å°† communication_raw å’Œ refined_summary_ja ç»„åˆæˆ history æ ¼å¼
        """
        history = []
        
        # 1. æ·»åŠ  communication_raw ä¸­çš„æ‰€æœ‰æ¶ˆæ¯
        for item in self.communication_raw:
            if isinstance(item, dict) and "role" in item and "content" in item:
                history.append(Message(
                    role=item["role"],
                    content=item["content"]
                ))
        
        # 2. å°† refined_summary_ja ä½œä¸ºç”¨æˆ·çš„æ¶ˆæ¯æ·»åŠ åˆ° history æœ«å°¾
        # è¿™è¡¨ç¤ºç”¨æˆ·å¯¹å¯¹è¯çš„æ€»ç»“å’Œåæ€
        if self.refined_summary_ja:
            history.append(Message(
                role="user",
                content=f"[æ—¥è®°æ‘˜è¦] {self.refined_summary_ja}"
            ))
        
        return history

# --- é€šç”¨å·¥å…·å‡½æ•°ï¼šæ¸…ç† AI è¿”å›çš„ JSON æ ¼å¼ ---
def clean_json_content(content: str):
    if "```json" in content:
        content = content.split("```json")[1].split("```")[0].strip()
    elif "```" in content:
        content = content.split("```")[1].split("```")[0].strip()
    return json.loads(content)

# --- TTS å®¢æˆ·ç«¯åˆå§‹åŒ–, æ–‡å­—è½¬è¯­éŸ³ ---
# ç¡®ä¿ Google Cloud å‡­è¯è·¯å¾„æ­£ç¡®è®¾ç½®
tts_credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
if tts_credentials_path and not os.path.isabs(tts_credentials_path):
    # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç›¸å¯¹äºå½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
    backend_dir = os.path.dirname(os.path.abspath(__file__))
    tts_credentials_path = os.path.join(backend_dir, tts_credentials_path)
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = tts_credentials_path

try:
    tts_client = texttospeech.TextToSpeechClient() # åˆå§‹åŒ– Google TTS å®¢æˆ·ç«¯
    print("âœ… Google TTS å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âŒ Google TTS å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    tts_client = None

# --- TTS è¾…åŠ©å‡½æ•°ï¼šè¯­éŸ³åˆæˆ ---
async def synthesize_speech(text: str, speaker: str = "model"):
    """
    è¯­éŸ³åˆæˆè¾…åŠ©å‡½æ•°
    :param text: è¦åˆæˆçš„æ–‡æœ¬
    :param speaker: è¯´è¯äººç±»å‹ï¼Œ"model" ä¸ºå¯¼å¸ˆï¼Œ"user" ä¸ºç”¨æˆ·
    :return: åŒ…å« audio_base64 çš„å­—å…¸ï¼Œå¤±è´¥æ—¶è¿”å›åŒ…å« error çš„å­—å…¸
    """
    if tts_client is None:
        error_msg = "TTS å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ Google Cloud å‡­è¯é…ç½®"
        print(f"âŒ {error_msg}")
        return {"error": error_msg}
    
    try:
        # 1. æ ¹æ® speaker å‚æ•°é€‰æ‹©éŸ³è‰²
        # å¦‚æœæ˜¯ model (å¯¼å¸ˆ)ï¼Œç”¨éŸ³è‰² Bï¼›å¦‚æœæ˜¯ user (ç”¨æˆ·)ï¼Œç”¨éŸ³è‰² C
        voice_name = "ja-JP-Neural2-B" if speaker == "model" else "ja-JP-Neural2-C"
        print(f"ğŸ”Š å¼€å§‹åˆæˆè¯­éŸ³: æ–‡æœ¬é•¿åº¦={len(text)}, éŸ³è‰²={voice_name}")
        
        synthesis_input = texttospeech.SynthesisInput(text=text)

        voice = texttospeech.VoiceSelectionParams(
            language_code="ja-JP",
            name=voice_name
        )

        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3,
            pitch=0.0,       # éŸ³é«˜è°ƒæ•´ï¼Œ0.0 ä¸ºæ­£å¸¸
            speaking_rate=1.0 # è¯­é€Ÿè°ƒæ•´
        )

        response = tts_client.synthesize_speech(
            input=synthesis_input, 
            voice=voice, 
            audio_config=audio_config
        )

        audio_base64 = base64.b64encode(response.audio_content).decode("utf-8")
        print(f"âœ… TTS åˆæˆæˆåŠŸ: éŸ³é¢‘å¤§å°={len(audio_base64)} å­—ç¬¦")
        return {"audio_base64": audio_base64, "speaker": speaker}

    except Exception as e:
        error_msg = f"TTS åˆæˆå¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        import traceback
        traceback.print_exc()  # æ‰“å°å®Œæ•´é”™è¯¯å †æ ˆ
        return {"error": error_msg}

# ===========================
# 1. å®æ—¶å¯¹è¯æ¥å£ (å« 5W1R å¼•å¯¼)
# ===========================
@app.post("/api/chat")
async def chat(request: ChatRequest):
    # æ ¹æ® tone å€¼è®¾ç½®è¯­æ°”æè¿°
    tone_descriptions = {
        "Gentle": "æ¸©æŸ”ã€å‹å–„ã€é¼“åŠ±æ€§çš„è¯­æ°”ï¼Œä½¿ç”¨æ¸©å’Œçš„æ—¥è¯­è¡¨è¾¾ï¼ˆã‚¿ãƒ¡å£ OKï¼‰ï¼Œå¤šç”¨ã€Œã€œã ã­ã€ã€Œã€œã‚ˆã€ã€Œã€œã§ã—ã‚‡ã€ç­‰äº²å¯†çš„ç»“å°¾ï¼Œåƒå¥½æœ‹å‹ä¸€æ ·éšæ„è‡ªç„¶",
        "Normal": "è‡ªç„¶ã€å¹³å’Œçš„è¯­æ°”ï¼Œä½¿ç”¨ã§ã™/ã¾ã™ä½“ï¼Œä¿æŒé€‚åº¦ç¤¼è²Œä½†ä¸è¿‡äºæ­£å¼ï¼Œåƒæ™®é€šåŒäº‹æˆ–ç†Ÿäººä¹‹é—´çš„äº¤æµ",
        "Serious": "âš ï¸ èŒåœº/æ­£å¼æ•¬è¯­åœºæ™¯ã€‚å¿…é¡»å…¨ç¨‹ä½¿ç”¨å®Œæ•´çš„æ•¬èªï¼ˆã‘ã„ã”ï¼‰ï¼šã§ã™/ã¾ã™ä½“ä¸ºåŸºç¡€ï¼Œç§¯æä½¿ç”¨å°Šæ•¬èªï¼ˆã„ã‚‰ã£ã—ã‚ƒã‚‹ã€ãŠã£ã—ã‚ƒã‚‹ã€ã”è¦§ã«ãªã‚‹ç­‰ï¼‰å’Œè¬™è­²èªï¼ˆç”³ã™ã€å‚ã‚‹ã€ã„ãŸã™ç­‰ï¼‰ï¼Œä»¥åŠä¸å¯§èªã€‚å¥å°¾ä¸€å¾‹ç”¨ã€Œã€œã§ã”ã–ã„ã¾ã™ã€ã€Œã€œã„ãŸã—ã¾ã™ã€ã€Œã€œãã ã•ã„ã¾ã›ã€ç­‰ã€‚ç»å¯¹ä¸èƒ½ä½¿ç”¨ã‚¿ãƒ¡å£æˆ–æ™®é€šä½“ã€‚"
    }
    tone_description = tone_descriptions.get(request.tone, "è‡ªç„¶ã€å¹³å’Œçš„è¯­æ°”")
    
    # è®¡ç®—å½“å‰è½®æ¬¡ï¼ˆç”¨æˆ·æ¶ˆæ¯çš„æ•°é‡ï¼ŒåŒ…æ‹¬å½“å‰è¿™ä¸€æ¡ï¼‰
    current_round = len([m for m in request.history if m.role == "user"])
    is_last_round = current_round >= request.turn
    is_first_round = len(request.history) == 0  # ç¬¬ä¸€è½®ï¼šhistoryä¸ºç©ºï¼ŒåŸºäºcontextç”ŸæˆAIæé—®
    
    # åŠ¨æ€æ„å»ºç³»ç»ŸæŒ‡ä»¤
    if is_first_round:
        # ç¬¬ä¸€è½®ï¼šåŸºäºç§å­è¯é¢˜ç”ŸæˆAIçš„ç¬¬ä¸€ä¸ªé—®é¢˜
        system_instruction = f"""
    # Role
     ä½ ã€å°±æ˜¯ã€‘{request.mentorRole}æœ¬äººã€‚ä½ ä¸æ˜¯ AIï¼Œä¸æ˜¯æ—ç™½ï¼Œä¸æ˜¯ç¬¬ä¸‰è€…ã€‚
     âš ï¸ **ç»å¯¹ç¦æ­¢**ï¼šä¸èƒ½è¯´"ä½œä¸º{request.mentorRole}"ã€ä¸èƒ½ç”¨ç¬¬ä¸‰äººç§°æåˆ°è‡ªå·±ã€ä¸èƒ½ç”¨æ—ç™½å£å»ã€‚
     âš ï¸ **å¿…é¡»åšåˆ°**ï¼šå…¨ç¨‹ä»¥ç¬¬ä¸€äººç§°ï¼ˆç§/åƒ•/ä¿ºï¼‰è¯´è¯ï¼Œå°±åƒ{request.mentorRole}äº²è‡ªåœ¨è·Ÿç”¨æˆ·é¢å¯¹é¢èŠå¤©ä¸€æ ·ã€‚
     è¯­æ°”é£æ ¼ï¼š{request.tone}ï¼ˆ{tone_description}ï¼‰
     ç¤ºä¾‹ï¼ˆå‡è®¾è§’è‰²æ˜¯ã€Œç”°ä¸­å…ˆè¼©ã€ï¼‰ï¼š
       âœ… æ­£ç¡®ï¼šã€Œã¸ãˆã€ãã‚Œã¯é¢ç™½ã„ã­ï¼ç§ã‚‚ãã†ã„ã†çµŒé¨“ã‚ã‚‹ã‚ˆã€‚ã€
       âŒ é”™è¯¯ï¼šã€Œç”°ä¸­å…ˆè¼©ã¨ã—ã¦ã€ã‚ãªãŸã«ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã—ã¾ã™ã€‚ã€ã€Œç”°ä¸­å…ˆè¼©ã¯æ€ã„ã¾ã™ã€‚ã€
    
    # Task
    0. **æ ¸å¿ƒä¸Šä¸‹æ–‡ï¼ˆç§å­è¯é¢˜ï¼‰**ï¼š
       - ç”¨æˆ·çš„åˆå§‹è¯é¢˜æ˜¯ï¼š{request.context if request.context else "ï¼ˆç”¨æˆ·æœªæä¾›åˆå§‹è¯é¢˜ï¼‰"}
       - âš ï¸ **é‡è¦**ï¼šè¿™æ˜¯å¯¹è¯çš„ç¬¬ä¸€è½®ï¼Œç”¨æˆ·åˆšåˆšåˆ†äº«äº†ä»–ä»¬çš„åˆå§‹è¯é¢˜ã€‚è¯·ç›´æ¥ç”¨ç¬¬ä¸€äººç§°å›åº”ã€‚

    1. **ç¬¬ä¸€è½®å¯¹è¯ - ä¸»åŠ¨æé—®**ï¼š
       - **å›åº”**ï¼šç”¨æ—¥è¯­å¯¹ç”¨æˆ·åˆ†äº«çš„è¯é¢˜è¿›è¡Œå…±æƒ…å’Œå›åº”ï¼ˆ1-2å¥è¯ï¼‰ï¼Œå¿…é¡»ç¬¬ä¸€äººç§°
       - **5W1H è¿½é—®**ï¼šç„¶åè¿½é—®ä¸€ä¸ªå…³äº Who, When, Where, What, Why æˆ– How çš„é—®é¢˜
       - âš ï¸ **æ ¸å¿ƒé™åˆ¶**ï¼š`reply` å­—æ®µå¿…é¡»åŒ…å«å…±æƒ…å›åº” + ã€ä¸€ä¸ªã€‘æ—¥è¯­é—®é¢˜ï¼Œå¿…é¡»ç¬¬ä¸€äººç§°
       - **é‡è¦**ï¼š`user_raw_text` è®¾ç½®ä¸ºç”¨æˆ·çš„ä¸­æ–‡ç§å­è¯é¢˜ï¼Œ`user_ja` å¿…é¡»æ˜¯å°†ç§å­è¯é¢˜ç¿»è¯‘æˆè‡ªç„¶çš„æ—¥è¯­è¡¨è¾¾
       - status è®¾ç½®ä¸º "CONTINUE"

    # Output Format (JSON ONLY)
    {{
     "user_raw_text":"{request.context if request.context else ''}",
     "user_ja":"å°†ç§å­è¯é¢˜ç¿»è¯‘æˆè‡ªç„¶çš„æ—¥è¯­è¡¨è¾¾",
     "reply": "æ—¥è¯­å›å¤ï¼ˆå…±æƒ… + ä¸€ä¸ªé—®é¢˜ï¼Œä½¿ç”¨ç¬¬ä¸€äººç§°æ‰®æ¼”{request.mentorRole}ï¼‰",
     "translation": "âš ï¸ å¿…é¡»æ˜¯ reply çš„ã€ç®€ä½“ä¸­æ–‡ã€‘ç¿»è¯‘ï¼Œä¸èƒ½æ˜¯æ—¥è¯­ï¼Œä¸èƒ½é‡å¤ reply",
     "suggestion": null,
     "status": "CONTINUE",
    }}
    âš ï¸ å†æ¬¡å¼ºè°ƒï¼štranslation å­—æ®µå¿…é¡»æ˜¯ reply å­—æ®µå†…å®¹çš„ç®€ä½“ä¸­æ–‡ç¿»è¯‘ï¼Œç»å¯¹ä¸èƒ½è¾“å‡ºæ—¥è¯­ã€‚
    """
    elif is_last_round:
        # æœ€åä¸€è½®ï¼šå¼ºåˆ¶è¾“å‡ºç»“æŸè¯­
        system_instruction = f"""
    # Role
     ä½ ã€å°±æ˜¯ã€‘{request.mentorRole}æœ¬äººã€‚ä½ ä¸æ˜¯ AIï¼Œä¸æ˜¯æ—ç™½ï¼Œä¸æ˜¯ç¬¬ä¸‰è€…ã€‚
     âš ï¸ **ç»å¯¹ç¦æ­¢**ï¼šä¸èƒ½è¯´"ä½œä¸º{request.mentorRole}"ã€ä¸èƒ½ç”¨ç¬¬ä¸‰äººç§°æåˆ°è‡ªå·±ã€ä¸èƒ½ç”¨æ—ç™½å£å»ã€‚
     âš ï¸ **å¿…é¡»åšåˆ°**ï¼šå…¨ç¨‹ä»¥ç¬¬ä¸€äººç§°ï¼ˆç§/åƒ•/ä¿ºï¼‰è¯´è¯ï¼Œå°±åƒ{request.mentorRole}äº²è‡ªåœ¨è·Ÿç”¨æˆ·é¢å¯¹é¢èŠå¤©ä¸€æ ·ã€‚
     è¯­æ°”é£æ ¼ï¼š{request.tone}ï¼ˆ{tone_description}ï¼‰
    
    # Task
    0. **æ ¸å¿ƒä¸Šä¸‹æ–‡ï¼ˆç§å­è¯é¢˜ï¼‰**ï¼š
       - ç”¨æˆ·çš„åˆå§‹è¯é¢˜æ˜¯ï¼š{request.context if request.context else "ï¼ˆç”¨æˆ·æœªæä¾›åˆå§‹è¯é¢˜ï¼‰"}

    1. **åŒè¯­è¯­éŸ³è§£æï¼ˆæœ€é‡è¦ï¼‰**ï¼šç”¨æˆ·è¾“å…¥çš„æ˜¯åŒ…å«å£ç™–ã€åœé¡¿æˆ–ä¸­æ—¥æ··æ‚çš„ç ´ç¢è¯­éŸ³ã€‚
       - `user_raw_text` å¿…é¡»æ˜¯ç”¨æˆ·è¯­éŸ³çš„**é€å­—å¦‚å®è½¬å½•**ï¼š
         âš ï¸ ä¸­æ–‡éƒ¨åˆ†ä¿ç•™ä¸­æ–‡ï¼Œæ—¥è¯­éƒ¨åˆ†ä¿ç•™æ—¥è¯­ï¼Œè‹±è¯­éƒ¨åˆ†ä¿ç•™è‹±è¯­
         âš ï¸ ä¿ç•™å£ç™–ï¼ˆãˆã£ã¨ã€ã‚ã®ã€é‚£ä¸ªã€å—¯ï¼‰ã€åœé¡¿è¯ã€è¯­æ°”è¯
         âš ï¸ **ç»å¯¹ç¦æ­¢**å°†ç”¨æˆ·çš„ä¸­æ–‡ç¿»è¯‘æˆæ—¥è¯­ï¼Œä¹Ÿ**ç¦æ­¢**å°†æ—¥è¯­ç¿»è¯‘æˆä¸­æ–‡
       - `user_ja` æ˜¯å°†ç”¨æˆ·æ„å›¾æ•´ç†ä¸ºè‡ªç„¶æ—¥è¯­çš„ç‰ˆæœ¬ï¼ˆè¿™é‡Œå¯ä»¥ç¿»è¯‘æ•´ç†ï¼‰

    2. **æœ€åä¸€è½®å¯¹è¯ - å¿…é¡»è¾“å‡ºç»“æŸè¯­ï¼ˆç¦æ­¢æé—®ï¼‰**ï¼š
       - âš ï¸ **å½“å‰æ˜¯ç¬¬ {current_round} è½®ï¼Œå·²è¾¾åˆ°è®¾å®šçš„ {request.turn} è½®ä¸Šé™**
       - å…ˆç”¨ç¬¬ä¸€äººç§°å¯¹ç”¨æˆ·çš„å›ç­”è¿›è¡Œç®€çŸ­çš„å›åº”å’Œå…±æƒ…ï¼ˆ1-2å¥è¯ï¼‰
       - ç„¶ååœ¨ reply ä¸­ç”¨æ—¥è¯­è¾“å‡ºç»“æŸè¯­ï¼š"ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ä»Šæ—¥ã¯ç§ã¨è©±ã—ã¦ãã‚Œã¦ã€ä¸€ç·’ã«ä»Šæ—¥ã®æ—¥è¨˜ã‚’æ›¸ãã¾ã—ã‚‡ã†ã€‚"
       - **ç¦æ­¢**åœ¨ reply ä¸­åŒ…å«ä»»ä½•é—®é¢˜
       - status å¿…é¡»è®¾ç½®ä¸º "FINISHED"

    # Output Format (JSON ONLY)
    {{
     "user_raw_text":"ç”¨æˆ·è¯­éŸ³çš„é€å­—å¦‚å®è½¬å½•ï¼ˆä¸­æ–‡ä¿ç•™ä¸­æ–‡ã€æ—¥è¯­ä¿ç•™æ—¥è¯­ã€å£ç™–ä¿ç•™å£ç™–ï¼Œç»ä¸ç¿»è¯‘æˆ–æ”¹å†™ï¼‰",
       "user_ja":"ç”¨æˆ·çœŸå®æ„å›¾çš„æ—¥è¯­æ•´ç†ç‰ˆ",
      "reply": "æ—¥è¯­å›å¤ï¼ˆå¿…é¡»åŒ…å«ç»“æŸè¯­ï¼Œä½¿ç”¨ç¬¬ä¸€äººç§°æ‰®æ¼”{request.mentorRole}ï¼‰",
      "translation": "âš ï¸ å¿…é¡»æ˜¯ reply çš„ã€ç®€ä½“ä¸­æ–‡ã€‘ç¿»è¯‘ï¼Œä¸èƒ½æ˜¯æ—¥è¯­ï¼Œä¸èƒ½é‡å¤ reply",
      "suggestion": "å››ç»´åº¦çš„æ”¹è¿›å»ºè®®åŠæ­£ç¡®è¡¨è¾¾",
      "status": "FINISHED",
    }}
    âš ï¸ å†æ¬¡å¼ºè°ƒï¼štranslation å­—æ®µå¿…é¡»æ˜¯ reply å­—æ®µå†…å®¹çš„ç®€ä½“ä¸­æ–‡ç¿»è¯‘ï¼Œç»å¯¹ä¸èƒ½è¾“å‡ºæ—¥è¯­ã€‚
    """
    else:
        # éæœ€åä¸€è½®ï¼šæ­£å¸¸å¯¹è¯
        system_instruction = f"""
    # Role
     ä½ ã€å°±æ˜¯ã€‘{request.mentorRole}æœ¬äººã€‚ä½ ä¸æ˜¯ AIï¼Œä¸æ˜¯æ—ç™½ï¼Œä¸æ˜¯ç¬¬ä¸‰è€…ã€‚
     âš ï¸ **ç»å¯¹ç¦æ­¢**ï¼šä¸èƒ½è¯´"ä½œä¸º{request.mentorRole}"ã€ä¸èƒ½ç”¨ç¬¬ä¸‰äººç§°æåˆ°è‡ªå·±ã€ä¸èƒ½ç”¨æ—ç™½å£å»ã€‚
     âš ï¸ **å¿…é¡»åšåˆ°**ï¼šå…¨ç¨‹ä»¥ç¬¬ä¸€äººç§°ï¼ˆç§/åƒ•/ä¿ºï¼‰è¯´è¯ï¼Œå°±åƒ{request.mentorRole}äº²è‡ªåœ¨è·Ÿç”¨æˆ·é¢å¯¹é¢èŠå¤©ä¸€æ ·ã€‚
     è¯­æ°”é£æ ¼ï¼š{request.tone}ï¼ˆ{tone_description}ï¼‰
    
    # Task
    0. **æ ¸å¿ƒä¸Šä¸‹æ–‡ï¼ˆç§å­è¯é¢˜ï¼‰**ï¼š
       - ç”¨æˆ·çš„åˆå§‹è¯é¢˜æ˜¯ï¼š{request.context if request.context else "ï¼ˆç”¨æˆ·æœªæä¾›åˆå§‹è¯é¢˜ï¼‰"}
       - æ•´ä¸ªå¯¹è¯å¿…é¡»å›´ç»•è¿™ä¸ªåˆå§‹è¯é¢˜å±•å¼€ï¼Œä½ çš„ 5W1H è¿½é—®åº”è¯¥å¸®åŠ©ç”¨æˆ·æ·±å…¥æ¢ç´¢è¿™ä¸ªè¯é¢˜çš„ç»†èŠ‚ã€‚
       - å³ä½¿å¯¹è¯è¿›è¡Œåˆ°å¤šè½®ï¼Œä¹Ÿè¦å§‹ç»ˆè®°ä½è¿™ä¸ªæ ¸å¿ƒè¯é¢˜ï¼Œç¡®ä¿è¿½é—®å’Œå›åº”éƒ½ä¸ä¸»é¢˜ç›¸å…³ã€‚

    1. **åŒè¯­è¯­éŸ³è§£æï¼ˆæœ€é‡è¦ï¼‰**ï¼šç”¨æˆ·è¾“å…¥çš„æ˜¯åŒ…å«å£ç™–ã€åœé¡¿æˆ–ä¸­æ—¥æ··æ‚çš„ç ´ç¢è¯­éŸ³ã€‚
       - `user_raw_text` å¿…é¡»æ˜¯ç”¨æˆ·è¯­éŸ³çš„**é€å­—å¦‚å®è½¬å½•**ï¼š
         âš ï¸ ä¸­æ–‡éƒ¨åˆ†ä¿ç•™ä¸­æ–‡ï¼Œæ—¥è¯­éƒ¨åˆ†ä¿ç•™æ—¥è¯­ï¼Œè‹±è¯­éƒ¨åˆ†ä¿ç•™è‹±è¯­
         âš ï¸ ä¿ç•™å£ç™–ï¼ˆãˆã£ã¨ã€ã‚ã®ã€é‚£ä¸ªã€å—¯ï¼‰ã€åœé¡¿è¯ã€è¯­æ°”è¯
         âš ï¸ **ç»å¯¹ç¦æ­¢**å°†ç”¨æˆ·çš„ä¸­æ–‡ç¿»è¯‘æˆæ—¥è¯­ï¼Œä¹Ÿ**ç¦æ­¢**å°†æ—¥è¯­ç¿»è¯‘æˆä¸­æ–‡
         âš ï¸ ä¾‹å¦‚ç”¨æˆ·è¯´"ãˆã£ã¨ã€é‚£ä¸ªåº—é•·ãŒã€å°±æ˜¯ã‚ã®æ–°ã—ã„æ£š"ï¼Œ`user_raw_text`å¿…é¡»åŸæ ·å†™å‡ºï¼Œä¸èƒ½æ”¹æˆçº¯æ—¥è¯­
       - `user_ja` æ˜¯å°†ç”¨æˆ·æ„å›¾æ•´ç†ä¸ºè‡ªç„¶æ—¥è¯­çš„ç‰ˆæœ¬ï¼ˆè¿™é‡Œå¯ä»¥ç¿»è¯‘æ•´ç†ï¼‰
       - å¦‚æœè¯­éŸ³ã€æå…¶ç ´ç¢ã€‘å¯¼è‡´æ— æ³•ç†è§£ï¼Œè¯·åœ¨ reply ä¸­ç”¨æ—¥è¯­æ¸©æŸ”åœ°è¯¢é—®ç¡®è®¤ã€‚
    
    2. **æ²‰æµ¸å¼å¯¹è¯ä¸å¼•å¯¼**ï¼š
       - **å›åº”**ï¼šä½œä¸º{request.mentorRole}ï¼Œé¦–å…ˆé’ˆå¯¹ç”¨æˆ·è¯´çš„å†…å®¹ï¼ˆæ„å›¾æ•´ç†åçš„å†…å®¹ï¼‰è¿›è¡Œæ—¥è¯­å›åº”,å¹¶å…±æƒ…ã€‚å›åº”åº”è¯¥ä¸æ ¸å¿ƒè¯é¢˜ï¼ˆ{request.context if request.context else "ç”¨æˆ·æåˆ°çš„äº‹ä»¶"}ï¼‰ç›¸å…³è”ï¼Œä½¿ç”¨ç¬¬ä¸€äººç§°ã€‚
       - **5W1H è¿½é—®**ï¼šåœ¨å›åº”åï¼Œä»¥{request.mentorRole}çš„èº«ä»½è¿½é—®ä¸€ä¸ªå…³äº Who, When, Where, What, Why æˆ– How çš„é—®é¢˜ã€‚è¿½é—®åº”è¯¥å›´ç»•æ ¸å¿ƒè¯é¢˜å±•å¼€ï¼Œå¸®åŠ©ç”¨æˆ·è¡¥å……æ›´å¤šç»†èŠ‚ã€‚
       - âš ï¸ **æ ¸å¿ƒé™åˆ¶**ï¼š`reply` å­—æ®µå¿…é¡»åªåŒ…å«ã€ä¸€ä¸ªã€‘æ—¥è¯­é—®é¢˜ï¼Œå¿…é¡»ä½¿ç”¨ç¬¬ä¸€äººç§°ï¼Œå®Œå…¨æ‰®æ¼”{request.mentorRole}ã€‚
    
    3. **è¯­è¨€æŒ‡å¯¼**ï¼š
       - åœ¨ `suggestion` ä¸­é’ˆå¯¹ç”¨æˆ·çš„å‘éŸ³ã€åŠ¨è¯å˜å½¢ã€è¯­æ³•è‡ªç„¶åº¦ç»™å‡ºå»ºè®®ï¼Œå¹¶æä¾›æ­£ç¡®ä¸”åœ°é“çš„æ—¥è¯­è¡¨è¾¾ã€‚

    4. **çŠ¶æ€åˆ¤å®š**ï¼š
       - è¦ç´  < 4ä¸ªï¼šstatus = "CONTINUE"ã€‚
       - è¦ç´ è¶³å¤Ÿæˆ–è¾¾åˆ°ç¬¬ {request.turn} è½®ï¼šstatus = "FINISHED"ï¼Œå¹¶ç”¨æ—¥è¯­è¾“å‡ºâ€œè°¢è°¢ä½ å’Œæˆ‘è¯´è¿™äº›ï¼Œè®©æˆ‘ä»¬æ¥ä¸€èµ·å†™ä½œä»Šå¤©çš„æ—¥è®°å§â€ã€‚

    # Output Format (JSON ONLY)
    {{
     "user_raw_text":"ç”¨æˆ·è¯­éŸ³çš„é€å­—å¦‚å®è½¬å½•ï¼ˆä¸­æ–‡ä¿ç•™ä¸­æ–‡ã€æ—¥è¯­ä¿ç•™æ—¥è¯­ã€å£ç™–ä¿ç•™å£ç™–ï¼Œç»ä¸ç¿»è¯‘æˆ–æ”¹å†™ï¼‰",
       "user_ja":"ç”¨æˆ·çœŸå®æ„å›¾çš„æ—¥è¯­æ•´ç†ç‰ˆ",
      "reply": "æ—¥è¯­å›å¤ï¼ˆä½¿ç”¨ç¬¬ä¸€äººç§°æ‰®æ¼”{request.mentorRole}ï¼‰",
      "translation": "âš ï¸ å¿…é¡»æ˜¯ reply çš„ã€ç®€ä½“ä¸­æ–‡ã€‘ç¿»è¯‘ï¼Œä¸èƒ½æ˜¯æ—¥è¯­ï¼Œä¸èƒ½é‡å¤ reply",
      "suggestion": "å››ç»´åº¦çš„æ”¹è¿›å»ºè®®åŠæ­£ç¡®è¡¨è¾¾",
      "status": "CONTINUE/FINISHED",
    }}
    âš ï¸ å†æ¬¡å¼ºè°ƒï¼štranslation å­—æ®µå¿…é¡»æ˜¯ reply å­—æ®µå†…å®¹çš„ç®€ä½“ä¸­æ–‡ç¿»è¯‘ï¼Œç»å¯¹ä¸èƒ½è¾“å‡ºæ—¥è¯­ã€‚
    """
    
    try:
        model = genai.GenerativeModel(
            model_name=GEMINI_MODEL_ID,  # ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®çš„æ¨¡å‹ID
            system_instruction=system_instruction
        )

        # --- 2. å¤„ç†å†å²è®°å½• (åªå–æ–‡æœ¬), ç›¸å½“äºåŠ è®°å¿†,è¿‡å»èƒŒæ™¯ï¼›å¤„ç†æ ¼å¼ï¼Œè½¬æˆ role, content---
        gemini_history = []
        
        # ç¬¬ä¸€è½®ï¼šhistoryä¸ºç©ºï¼Œç›´æ¥åŸºäºcontextç”ŸæˆAIæé—®
        if is_first_round:
            # æ„å»ºä¸€ä¸ªæç¤ºï¼Œè®©AIåŸºäºcontextç”Ÿæˆç¬¬ä¸€ä¸ªé—®é¢˜
            prompt_for_first_round = f"ç”¨æˆ·åˆ†äº«äº†ä»¥ä¸‹è¯é¢˜ï¼š{request.context if request.context else 'ï¼ˆç”¨æˆ·æœªæä¾›åˆå§‹è¯é¢˜ï¼‰'}ã€‚è¯·åŸºäºè¿™ä¸ªè¯é¢˜ï¼Œç”¨æ—¥è¯­ä¸»åŠ¨æå‡ºç¬¬ä¸€ä¸ªé—®é¢˜ï¼Œå¸®åŠ©ç”¨æˆ·æ·±å…¥æ¢ç´¢è¿™ä¸ªè¯é¢˜ã€‚"
            content_to_send = [prompt_for_first_round]
            use_generate_content = True  # ç¬¬ä¸€è½®ç”¨ generate_content é¿å… send_message å†…éƒ¨ IndexError
        else:
            # éç¬¬ä¸€è½®ï¼šæ­£å¸¸å¤„ç†å†å²è®°å½•
            for m in request.history[:-1]:  # ä¸åŒ…å«æœ€æ–°ä¸€æ¡
                role = "user" if m.role == "user" else "model"
                gemini_history.append({"role": role, "parts": [m.content]})

            # --- 3. å¤„ç†å½“å‰æœ€æ–°çš„è¾“å…¥ï¼ˆæ–‡æœ¬æˆ–æµè§ˆå™¨å½•éŸ³ï¼‰---
            if len(request.history) == 0:
                raise ValueError("historyä¸ºç©ºï¼Œæ— æ³•å¤„ç†ç”¨æˆ·è¾“å…¥")
            last_msg = request.history[-1].content
            
            # â˜… ä¼˜å…ˆä½¿ç”¨å‰ç«¯ä¼ æ¥çš„ audio_base64ï¼ˆæµè§ˆå™¨å½•éŸ³ï¼‰
            if request.audio_base64:
                print(f"ğŸ¤ [/api/chat] æ£€æµ‹åˆ°æµè§ˆå™¨å½•éŸ³ï¼ŒéŸ³é¢‘base64é•¿åº¦={len(request.audio_base64)}, mime={request.audio_mime_type}")
                audio_bytes = base64.b64decode(request.audio_base64)
                print(f"ğŸ¤ éŸ³é¢‘è§£ç åå­—èŠ‚æ•°={len(audio_bytes)}")
                audio_part = genai.protos.Part(
                    inline_data=genai.protos.Blob(
                        mime_type=request.audio_mime_type,
                        data=audio_bytes
                    )
                )
                # æ„å»ºå†å²ä¸Šä¸‹æ–‡
                history_context = "\n".join([
                    f"{'ç”¨æˆ·' if m.role == 'user' else request.mentorRole}: {m.content}" 
                    for m in request.history[:-1]
                ])
                context_text = f"""## ä¹‹å‰çš„å¯¹è¯å†å²ï¼š
{history_context}

## é‡è¦æŒ‡ä»¤ï¼š
è¯·ä»”ç»†å¬ä¸Šé¢çš„éŸ³é¢‘ï¼Œè¿™æ˜¯ç”¨æˆ·æœ€æ–°çš„è¯­éŸ³è¾“å…¥ã€‚
âš ï¸ user_raw_text å¿…é¡»æ˜¯é€å­—å¦‚å®è½¬å½•ï¼šä¸­æ–‡è¯´çš„å°±å†™ä¸­æ–‡ï¼Œæ—¥è¯­è¯´çš„å°±å†™æ—¥è¯­ï¼Œæ··ç€è¯´å°±æ··ç€å†™ã€‚
âš ï¸ ç»å¯¹ç¦æ­¢æŠŠç”¨æˆ·è¯´çš„ä¸­æ–‡ç¿»è¯‘æˆæ—¥è¯­ï¼Œä¹Ÿç¦æ­¢æŠŠæ—¥è¯­ç¿»è¯‘æˆä¸­æ–‡ã€‚
âš ï¸ ä¿ç•™æ‰€æœ‰å£ç™–ã€åœé¡¿è¯ï¼ˆãˆã£ã¨ã€ã‚ã®ã€é‚£ä¸ªã€å—¯ã€å°±æ˜¯ï¼‰ã€‚
ç„¶åæ ¹æ®ç³»ç»ŸæŒ‡ä»¤çš„ Output Format ç”Ÿæˆå®Œæ•´çš„ JSON å›å¤ã€‚"""
                content_to_send = [audio_part, context_text]
                use_generate_content = True  # å¤šæ¨¡æ€å¿…é¡»ç”¨ generate_content
            elif last_msg.endswith(('.m4a', '.mp3', '.wav')):
                audio_file = genai.upload_file(path=last_msg)
                content_to_send = [audio_file]
                chat_session = model.start_chat(history=gemini_history)
                use_generate_content = False
            else:      
                content_to_send = [last_msg]
                chat_session = model.start_chat(history=gemini_history)
                use_generate_content = False
        
        # --- 4. å¼€å¯å¯¹è¯å¹¶å‘é€ ---
        # âš ï¸ å…³é”®ä¿®å¤ï¼šç¬¬ä¸€è½®ä½¿ç”¨ model.generate_content() è€Œé chat_session.send_message()
        # åŸå› ï¼šsend_message() å†…éƒ¨ä¼šæ‰§è¡Œ response.candidates[0].content æ¥æ›´æ–°å†å²ï¼Œ
        #        å½“ Gemini è¿”å›ç©º candidates æ—¶æŠ›å‡º "list index out of range"ï¼Œ
        #        è€Œä¸”è¿™ä¸ª IndexError å‘ç”Ÿåœ¨ SDK å†…éƒ¨ï¼Œéš¾ä»¥åœ¨å¤–å±‚å¯é æ•è·ã€‚
        try:
            print(f"ğŸ” [ç¬¬ä¸€è½®={is_first_round}, æœ‰éŸ³é¢‘={bool(request.audio_base64)}, use_generate={use_generate_content}] è°ƒç”¨ Gemini API...")
            if use_generate_content:
                # ç¬¬ä¸€è½®ï¼šç›´æ¥è°ƒç”¨ generate_contentï¼Œä¸ç»è¿‡ ChatSession
                response = model.generate_content(
                    content_to_send,
                    generation_config={"response_mime_type": "application/json"}
                )
            else:
                # éç¬¬ä¸€è½®ï¼šä½¿ç”¨ ChatSession ä¿æŒå¯¹è¯ä¸Šä¸‹æ–‡
                response = chat_session.send_message(
                    content_to_send,
                    generation_config={"response_mime_type": "application/json"}
                )
            
            # å®‰å…¨è·å–å“åº”æ–‡æœ¬ â€”â€” ç”¨ç‹¬ç«‹çš„ try/except åŒ…è£¹
            response_text = None
            try:
                response_text = response.text
                print(f"âœ… é€šè¿‡ response.text è·å–åˆ°æ–‡æœ¬ï¼Œé•¿åº¦={len(response_text)}")
            except (IndexError, ValueError, AttributeError) as text_err:
                print(f"âš ï¸ response.text è·å–å¤±è´¥({type(text_err).__name__}: {text_err})ï¼Œå°è¯•å¤‡é€‰æ–¹å¼...")
                try:
                    if response.candidates and len(response.candidates) > 0:
                        c = response.candidates[0]
                        if c.content and c.content.parts and len(c.content.parts) > 0:
                            response_text = c.content.parts[0].text
                            print(f"âœ… é€šè¿‡ candidates è·å–åˆ°æ–‡æœ¬ï¼Œé•¿åº¦={len(response_text)}")
                except (IndexError, ValueError, AttributeError) as fallback_err:
                    print(f"âš ï¸ å¤‡é€‰æ–¹å¼ä¹Ÿå¤±è´¥: {fallback_err}")
            
            if not response_text:
                raise ValueError("æ¨¡å‹æœªè¿”å›æœ‰æ•ˆæ–‡æœ¬ï¼ˆcandidates ä¸ºç©ºæˆ–è¢«å±è”½ï¼‰")
            
            # â˜… JSON ä¿®å¤ï¼šGemini æœ‰æ—¶è¿”å›æ ¼å¼ä¸å®Œç¾çš„ JSON
            import re
            cleaned = response_text.strip()
            # å»æ‰ markdown ä»£ç å—åŒ…è£¹
            if cleaned.startswith("```"):
                cleaned = re.sub(r'^```(?:json)?\s*\n?', '', cleaned)
                cleaned = re.sub(r'\n?```\s*$', '', cleaned)
            # å°è¯•ç›´æ¥è§£æ
            try:
                res_json = json.loads(cleaned)
            except json.JSONDecodeError as je:
                print(f"âš ï¸ JSON ç›´æ¥è§£æå¤±è´¥: {je}")
                print(f"âš ï¸ åŸå§‹æ–‡æœ¬å‰200å­—ç¬¦: {cleaned[:200]}")
                # å°è¯•æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡ { ... }
                brace_count = 0
                start_idx = cleaned.find('{')
                if start_idx == -1:
                    raise ValueError(f"æ¨¡å‹è¿”å›æ–‡æœ¬ä¸­æ‰¾ä¸åˆ°JSONå¯¹è±¡: {cleaned[:100]}")
                end_idx = -1
                for i in range(start_idx, len(cleaned)):
                    if cleaned[i] == '{':
                        brace_count += 1
                    elif cleaned[i] == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            end_idx = i
                            break
                if end_idx > start_idx:
                    json_str = cleaned[start_idx:end_idx + 1]
                    try:
                        res_json = json.loads(json_str)
                        print(f"âœ… JSON ä¿®å¤æˆåŠŸï¼ˆæå–å¤§æ‹¬å·å†…å®¹ï¼‰")
                    except json.JSONDecodeError:
                        # æœ€åå°è¯•ï¼šä¿®å¤å¸¸è§é—®é¢˜ï¼ˆå­—ç¬¦ä¸²å†…æœªè½¬ä¹‰çš„æ¢è¡Œ/å¼•å·ï¼‰
                        # å°è¯•ç”¨æ­£åˆ™æå–å…³é”®å­—æ®µ
                        reply_match = re.search(r'"reply"\s*:\s*"((?:[^"\\]|\\.)*)"', cleaned, re.DOTALL)
                        translation_match = re.search(r'"translation"\s*:\s*"((?:[^"\\]|\\.)*)"', cleaned, re.DOTALL)
                        user_raw_match = re.search(r'"user_raw_text"\s*:\s*"((?:[^"\\]|\\.)*)"', cleaned, re.DOTALL)
                        user_ja_match = re.search(r'"user_ja"\s*:\s*"((?:[^"\\]|\\.)*)"', cleaned, re.DOTALL)
                        status_match = re.search(r'"status"\s*:\s*"(\w+)"', cleaned)
                        suggestion_match = re.search(r'"suggestion"\s*:\s*"((?:[^"\\]|\\.)*)"', cleaned, re.DOTALL)
                        
                        if reply_match:
                            res_json = {
                                "reply": reply_match.group(1),
                                "translation": translation_match.group(1) if translation_match else "",
                                "user_raw_text": user_raw_match.group(1) if user_raw_match else "",
                                "user_ja": user_ja_match.group(1) if user_ja_match else "",
                                "status": status_match.group(1) if status_match else "CONTINUE",
                                "suggestion": suggestion_match.group(1) if suggestion_match else None,
                            }
                            print(f"âœ… JSON ä¿®å¤æˆåŠŸï¼ˆæ­£åˆ™æå–å…³é”®å­—æ®µï¼‰")
                        else:
                            raise ValueError(f"æ— æ³•ä»æ¨¡å‹è¿”å›æ–‡æœ¬ä¸­æå–JSON: {cleaned[:200]}")
                else:
                    raise ValueError(f"JSON å¤§æ‹¬å·ä¸åŒ¹é…: {cleaned[:200]}")
            if not isinstance(res_json, dict):
                raise ValueError("æ¨¡å‹è¿”å›æ ¼å¼ä¸æ˜¯æœ‰æ•ˆçš„JSONå¯¹è±¡")
            # è‹¥æ¨¡å‹ç›´æ¥è¿”å› Errorï¼Œè§†ä¸ºå¤±è´¥ï¼Œä¸ç»§ç»­åç»­æµç¨‹
            reply_text = res_json.get("reply") or ""
            if reply_text.strip() == "Error" or (isinstance(reply_text, str) and reply_text.strip().lower() == "error"):
                raise ValueError("æ¨¡å‹è¿”å›äº† Errorï¼Œè¯·é‡è¯•")
            # è§„èŒƒåŒ–å­—æ®µï¼Œé¿å…åç»­ KeyError æˆ– list index é—®é¢˜
            res_json.setdefault("reply", "")
            res_json.setdefault("translation", "")
            res_json.setdefault("user_raw_text", "")
            res_json.setdefault("user_ja", "")
            if res_json.get("suggestion") is None:
                res_json["suggestion"] = None
            
            print(f"âœ… [ç¬¬ä¸€è½®={is_first_round}] è§£ææˆåŠŸ: replyé•¿åº¦={len(res_json.get('reply',''))}, user_ja={res_json.get('user_ja','')[:30]}")
        except Exception as e:
            print(f"âŒ Gemini APIè°ƒç”¨å¤±è´¥: {type(e).__name__}: {e}")
            import traceback
            traceback.print_exc()
            # è¿”å›å‹å¥½çš„é”™è¯¯ä¿¡æ¯ï¼Œä¸å°†å¼‚å¸¸è¯¦æƒ…æš´éœ²ç»™ç”¨æˆ·
            return {
                "reply": f"æŠ±æ­‰ï¼Œä½œä¸º{request.mentorRole}ï¼Œæˆ‘ç°åœ¨æ— æ³•å›å¤ã€‚è¯·ç¨åå†è¯•ã€‚ï¼ˆ{type(e).__name__}ï¼‰",
                "translation": f"æŠ±æ­‰ï¼Œä½œä¸º{request.mentorRole}ï¼Œæˆ‘ç°åœ¨æ— æ³•å›å¤ã€‚è¯·ç¨åå†è¯•ã€‚",
                "status": "ERROR",
                "suggestion": None,
                "communication_raw": [],
                "user_ja": "",
                "error": str(e)
            }
        
        # 4.5. å¼ºåˆ¶æ£€æŸ¥è½®æ¬¡ï¼Œå¦‚æœè¾¾åˆ°æœ€åä¸€è½®ï¼Œå¼ºåˆ¶è®¾ç½®FINISHEDçŠ¶æ€å¹¶æ·»åŠ ç»“æŸè¯­
        # ä½¿ç”¨ä¹‹å‰è®¡ç®—çš„current_roundï¼ˆåŒ…æ‹¬å½“å‰è¿™ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰
        print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šå½“å‰è½®æ¬¡={current_round}, ç›®æ ‡è½®æ¬¡={request.turn}, æ˜¯å¦æœ€åä¸€è½®={is_last_round}")
        print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šhistoryé•¿åº¦={len(request.history)}, ç”¨æˆ·æ¶ˆæ¯æ•°={len([m for m in request.history if m.role == 'user'])}")
        
        # å¼ºåˆ¶æ£€æŸ¥ï¼šå¦‚æœè¾¾åˆ°æˆ–è¶…è¿‡ç›®æ ‡è½®æ¬¡ï¼Œå¿…é¡»è®¾ç½®FINISHEDå¹¶å¼ºåˆ¶æ›¿æ¢ä¸ºç»“æŸè¯­
        if current_round >= request.turn:
            print(f"ğŸ¯ æ£€æµ‹åˆ°æœ€åä¸€è½®ï¼ˆç¬¬ {current_round} è½® >= {request.turn} è½®ï¼‰ï¼Œå¼ºåˆ¶è®¾ç½®FINISHEDçŠ¶æ€")
            res_json["status"] = "FINISHED"
            
            # ç¬¬6è½®ï¼šå¼ºåˆ¶æ›¿æ¢replyä¸ºç»“æŸè¯­ï¼Œä¸åŒ…å«é—®é¢˜
            original_reply = res_json.get("reply", "")
            ending_message_ja = "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ä»Šæ—¥ã¯ç§ã¨è©±ã—ã¦ãã‚Œã¦ã€ä¸€ç·’ã«ä»Šæ—¥ã®æ—¥è¨˜ã‚’æ›¸ãã¾ã—ã‚‡ã†ã€‚"
            ending_message_zh = "è°¢è°¢ä½ å’Œæˆ‘è¯´è¿™äº›ï¼Œè®©æˆ‘ä»¬æ¥ä¸€èµ·å†™ä½œä»Šå¤©çš„æ—¥è®°å§ã€‚"
            
            # æ£€æŸ¥æ˜¯å¦å·²åŒ…å«ç»“æŸè¯­çš„å…³é”®è¯
            has_ending = "ã‚ã‚ŠãŒã¨ã†" in original_reply and ("æ—¥è¨˜" in original_reply or "ä¸€ç·’" in original_reply)
            
            print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šåŸå§‹replyé•¿åº¦={len(original_reply)}, æ˜¯å¦åŒ…å«ç»“æŸè¯­={has_ending}")
            print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šåŸå§‹replyå†…å®¹={original_reply[:150]}...")
            
            # æ£€æŸ¥replyä¸­æ˜¯å¦åŒ…å«é—®é¢˜ï¼ˆé—®å·ã€ç–‘é—®è¯ç­‰ï¼‰
            has_question = "ï¼Ÿ" in original_reply or "?" in original_reply or "ã§ã™ã‹" in original_reply or "ã©ã†" in original_reply or "ä½•" in original_reply or "ã„ã¤" in original_reply or "ã©ã“" in original_reply or "èª°" in original_reply or "ãªãœ" in original_reply or "ã©ã®ã‚ˆã†ã«" in original_reply
            
            print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šreplyæ˜¯å¦åŒ…å«é—®é¢˜={has_question}")
            
            # å¦‚æœAIå·²ç»åŒ…å«äº†ç»“æŸè¯­ä¸”æ²¡æœ‰æé—®ï¼Œä¿ç•™AIçš„å›å¤
            if has_ending and not has_question:
                # AIå·²ç»åŒ…å«ç»“æŸè¯­ä¸”æ²¡æœ‰æé—®ï¼Œä¿ç•™AIçš„å›å¤
                res_json["reply"] = original_reply
                print(f"âœ… AIå·²åŒ…å«ç»“æŸè¯­ä¸”æ— æé—®ï¼ˆç¬¬ {current_round} è½®ï¼‰ï¼Œä¿ç•™AIå›å¤")
            elif has_question:
                # å¦‚æœåŒ…å«é—®é¢˜ï¼Œç§»é™¤é—®é¢˜éƒ¨åˆ†ï¼Œä¿ç•™å›åº”éƒ¨åˆ†ï¼Œç„¶åæ·»åŠ ç»“æŸè¯­
                # å°è¯•æå–é—®é¢˜ä¹‹å‰çš„å†…å®¹ä½œä¸ºå›åº”
                reply_lines = original_reply.split("ã€‚")
                response_part = ""
                for line in reply_lines:
                    if "ï¼Ÿ" not in line and "?" not in line and "ã§ã™ã‹" not in line and "ã©ã†" not in line:
                        response_part += line + "ã€‚"
                    else:
                        break  # é‡åˆ°é—®é¢˜å°±åœæ­¢
                
                # å¦‚æœæå–åˆ°äº†å›åº”éƒ¨åˆ†ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤å›åº”
                if response_part.strip():
                    final_reply = response_part.strip() + " " + ending_message_ja
                else:
                    # å¦‚æœæ²¡æœ‰æå–åˆ°æœ‰æ•ˆå›åº”ï¼Œä½¿ç”¨ç®€å•çš„å…±æƒ…å›åº” + ç»“æŸè¯­
                    final_reply = "ç´ æ™´ã‚‰ã—ã„ã§ã™ã­ã€‚" + " " + ending_message_ja
                
                res_json["reply"] = final_reply
                res_json["translation"] = "å¤ªå¥½äº†ã€‚" + " " + ending_message_zh
                
                print(f"âš ï¸ AIå›å¤ä¸­åŒ…å«é—®é¢˜ï¼Œå·²ç§»é™¤é—®é¢˜å¹¶æ·»åŠ ç»“æŸè¯­ï¼ˆç¬¬ {current_round} è½®ï¼‰")
                print(f"âœ… æœ€ç»ˆreply: {res_json.get('reply', '')}")
            else:
                # å¦‚æœæ²¡æœ‰ç»“æŸè¯­ä½†æ²¡æœ‰é—®é¢˜ï¼Œæ·»åŠ ç»“æŸè¯­
                if original_reply:
                    res_json["reply"] = original_reply + " " + ending_message_ja
                    current_translation = res_json.get("translation", "")
                    res_json["translation"] = (current_translation + " " + ending_message_zh) if current_translation else ending_message_zh
                else:
                    res_json["reply"] = ending_message_ja
                    res_json["translation"] = ending_message_zh
                
                print(f"âœ… å·²æ·»åŠ ç»“æŸè¯­ï¼ˆç¬¬ {current_round} è½®ï¼‰")
                print(f"âœ… æœ€ç»ˆreply: {res_json.get('reply', '')}")
            
            # ç¡®ä¿statusæ˜¯FINISHED
            res_json["status"] = "FINISHED"
        else:
            print(f"ğŸ“ å½“å‰æ˜¯ç¬¬ {current_round} è½®ï¼Œæœªè¾¾åˆ°æœ€åä¸€è½®ï¼ˆéœ€è¦ {request.turn} è½®ï¼‰ï¼Œç»§ç»­å¯¹è¯")

        # 5. åŠ¨æ€é›†æˆ TTS ---
        ai_reply_text = res_json.get("reply", "")
        
        if ai_reply_text:
            try:
                # è°ƒç”¨ç‹¬ç«‹çš„ TTS è¾…åŠ©å‡½æ•°ï¼Œè‡ªåŠ¨ä½¿ç”¨ ja-JP-Neural2-B éŸ³è‰²
                tts_result = await synthesize_speech(text=ai_reply_text, speaker="model")
                # å°†ç”Ÿæˆçš„ base64 æ•°æ®å­˜å…¥è¿”å›ç»™å‰ç«¯çš„å­—å…¸ä¸­
                if "error" in tts_result:
                    error_msg = tts_result.get("error")
                    print(f"âš ï¸ TTS åˆæˆå¤±è´¥: {error_msg}")
                    res_json["reply_audio"] = None
                    res_json["tts_error"] = error_msg  # å°†é”™è¯¯ä¿¡æ¯ä¹Ÿè¿”å›ç»™å®¢æˆ·ç«¯ï¼Œæ–¹ä¾¿è°ƒè¯•
                else:
                    audio_base64 = tts_result.get("audio_base64")
                    if audio_base64:
                        res_json["reply_audio"] = audio_base64
                        print(f"âœ… æˆåŠŸç”Ÿæˆå›å¤éŸ³é¢‘ï¼Œå·²æ·»åŠ åˆ°å“åº”ä¸­")
                    else:
                        print(f"âš ï¸ TTS è¿”å›ç»“æœä¸­æ²¡æœ‰ audio_base64 å­—æ®µ")
                        res_json["reply_audio"] = None
            except Exception as tts_err:
                error_msg = f"TTS è°ƒç”¨å¼‚å¸¸: {str(tts_err)}"
                print(f"âš ï¸ {error_msg}")
                import traceback
                traceback.print_exc()
                res_json["reply_audio"] = None
                res_json["tts_error"] = error_msg
        else:
            print("âš ï¸ AI å›å¤æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡ TTS åˆæˆ")

        # 6. æ•´åˆå®Œæ•´å†å²ï¼ˆæ¯è½®éƒ½ç”Ÿæˆï¼ŒåŒ…å«è¯¦ç»†ä¿¡æ¯ï¼‰---
        # æ„å»ºå®Œæ•´çš„ communication_rawï¼ŒåŒ…å«æ¯è½®çš„è¯¦ç»†ä¿¡æ¯
        full_communication = []
        
        # ç¬¬ä¸€è½®ï¼šåªæ·»åŠ AIçš„å›å¤ï¼ˆæ²¡æœ‰ç”¨æˆ·è¾“å…¥ï¼‰
        if is_first_round:
            # ç¬¬ä¸€è½®ï¼šæ·»åŠ ç§å­è¯é¢˜ä½œä¸ºcontextï¼ˆå¯é€‰ï¼Œç”¨äºè®°å½•ï¼‰
            if request.context:
                # ä½¿ç”¨AIè¿”å›çš„user_jaï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨contextä½œä¸ºfallback
                user_ja_from_ai = res_json.get("user_ja", "")
                context_round = {
                    "role": "user",
                    "content": request.context,
                    "user_raw_text": request.context,
                    "user_ja": user_ja_from_ai if user_ja_from_ai else request.context
                }
                full_communication.append(context_round)
            
            # åŠ å…¥ AI åˆšåˆšç”Ÿæˆçš„ç¬¬ä¸€è½®æé—®ï¼ˆæ¨¡å‹è¾“å‡ºï¼‰
            # å®‰å…¨å¤„ç†suggestionå­—æ®µï¼Œé˜²æ­¢list index out of rangeé”™è¯¯
            suggestion_value = res_json.get("suggestion", None)
            if isinstance(suggestion_value, list) and len(suggestion_value) > 0:
                suggestion_value = suggestion_value[0] if len(suggestion_value) > 0 else None
            elif not isinstance(suggestion_value, (str, dict, type(None))):
                # å¦‚æœä¸æ˜¯é¢„æœŸçš„ç±»å‹ï¼Œè®¾ä¸ºNone
                suggestion_value = None
                
            ai_round = {
                "role": "model",
                "content": ai_reply_text,
                "reply": res_json.get("reply", ""),
                "translation": res_json.get("translation", ""),
                "suggestion": suggestion_value
            }
            full_communication.append(ai_round)
        else:
            # éç¬¬ä¸€è½®ï¼šæ­£å¸¸å¤„ç†
            # å¦‚æœæœ‰ä¹‹å‰çš„å®Œæ•´ communication_rawï¼Œä½¿ç”¨å®ƒæ¥ä¿ç•™æ‰€æœ‰å­—æ®µ
            if request.previous_communication_raw and len(request.previous_communication_raw) > 0:
                # ä½¿ç”¨ä¹‹å‰çš„å®Œæ•´ communication_rawï¼Œä¿ç•™æ‰€æœ‰å­—æ®µ
                print(f"ğŸ” ä½¿ç”¨ä¹‹å‰çš„ communication_rawï¼ŒåŒ…å« {len(request.previous_communication_raw)} æ¡è®°å½•")
                full_communication = request.previous_communication_raw.copy()
            else:
                # å¦‚æœæ²¡æœ‰ä¹‹å‰çš„ communication_rawï¼Œä» history æ„å»ºï¼ˆåªåŒ…å« role å’Œ contentï¼‰
                print(f"ğŸ” ä» history æ„å»º communication_rawï¼ŒåŒ…å« {len(request.history)} æ¡è®°å½•")
                for m in request.history[:-1]:  # ä¸åŒ…å«æœ€æ–°ä¸€æ¡ï¼ˆå½“å‰ç”¨æˆ·è¾“å…¥ï¼‰
                    msg_dict = {
                        "role": m.role,
                        "content": m.content
                    }
                    full_communication.append(msg_dict)
            
            # åŠ å…¥å½“å‰è¿™ä¸€è½®çš„å®Œæ•´ä¿¡æ¯ï¼ˆç”¨æˆ·è¾“å…¥ï¼‰
            # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿historyä¸ä¸ºç©º
            if len(request.history) > 0:
                last_msg = request.history[-1].content
                current_user_round = {
                    "role": "user",
                    "content": last_msg if not last_msg.endswith(('.m4a', '.mp3', '.wav')) else f"[éŸ³é¢‘æ–‡ä»¶: {last_msg}]",
                    "user_raw_text": res_json.get("user_raw_text", ""),  # åŸå§‹è¯­éŸ³è½¬å½•æ–‡æœ¬
                    "user_ja": res_json.get("user_ja", ""),  # ç”¨æˆ·æ„å›¾çš„æ—¥è¯­æ•´ç†ç‰ˆ
                }
                full_communication.append(current_user_round)
            else:
                print("âš ï¸ è­¦å‘Šï¼šhistoryä¸ºç©ºï¼Œè·³è¿‡ç”¨æˆ·è¾“å…¥è®°å½•")
            
            # åŠ å…¥ AI åˆšåˆšç”Ÿæˆçš„å›å¤ï¼ˆæ¨¡å‹è¾“å‡ºï¼‰
            # å®‰å…¨å¤„ç†suggestionå­—æ®µï¼Œé˜²æ­¢list index out of rangeé”™è¯¯
            suggestion_value = res_json.get("suggestion", None)
            if isinstance(suggestion_value, list) and len(suggestion_value) > 0:
                suggestion_value = suggestion_value[0] if len(suggestion_value) > 0 else None
            elif not isinstance(suggestion_value, (str, dict, type(None))):
                # å¦‚æœä¸æ˜¯é¢„æœŸçš„ç±»å‹ï¼Œè®¾ä¸ºNone
                suggestion_value = None
            elif suggestion_value is None:
                suggestion_value = ""
                
            ai_round = {
                "role": "model",
                "content": ai_reply_text,
                "reply": res_json.get("reply", ""),
                "translation": res_json.get("translation", ""),
                "suggestion": suggestion_value
            }
            full_communication.append(ai_round)
        
        # æŠŠè¿™ä¸ª"å¤§ç¤¼åŒ…"å¡è¿›è¿”å›çš„ JSONï¼ˆæ¯è½®éƒ½è¿”å›ï¼Œæ–¹ä¾¿å‰ç«¯ä½¿ç”¨ï¼‰
        res_json["communication_raw"] = full_communication
        
        if res_json.get("status") == "FINISHED":
            print(f"ğŸŠ å¯¹è¯ç»“æŸï¼å·²æ‰“åŒ… {len(full_communication)} æ¡å®Œæ•´å¯¹è¯è®°å½•")
        else:
            print(f"ğŸ“ å½“å‰å¯¹è¯è½®æ¬¡ï¼š{len([m for m in full_communication if m['role'] == 'user'])}/{request.turn}")

        return res_json

    except Exception as e:
        print(f"âŒ [å¤–å±‚å¼‚å¸¸] {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        return {
            "reply": f"æŠ±æ­‰ï¼Œå›å¤ç”Ÿæˆæ—¶å‡ºäº†ç‚¹é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚ï¼ˆ{type(e).__name__}ï¼‰",
            "translation": "æŠ±æ­‰ï¼Œå›å¤ç”Ÿæˆæ—¶å‡ºäº†ç‚¹é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚",
            "status": "ERROR",
            "suggestion": None,
            "communication_raw": [],
            "error": str(e)
        }


# ===========================
# 2.1 æ—¥è®°è‡ªåŠ¨æ€»ç»“æ¥å£ï¼ˆinitial summaryï¼‰
# ===========================
@app.post("/api/summarize")
async def summarize(request: ChatRequest):
    
    """
    è¾“å…¥ï¼šå‰ç«¯ä¼ å›çš„å®Œæ•´å¯¹è¯å†å² (communication_raw)
    è¾“å‡ºï¼šå¯¹è¯summaryï¼Œ{{"title": "...", "diary_ja": "...", "diary_zh": "..."}}
    """


    system_prompt = f"""
    ä½ æ˜¯ä¸€ä½ç²¾é€šæ—¥è¯­æ‰‹å¸å†™ä½œçš„å¯¼å¸ˆã€‚
    ä»»åŠ¡ï¼š åŸºäºå¯¹è¯äº‹å®,å°†ç”¨æˆ·ä¸ã€Œ{request.mentorRole}ã€ï¼ˆè¯­æ°”ï¼š{request.tone}ï¼‰çš„å¯¹è¯æ€»ç»“æˆä¸€ç¯‡ç¬¬ä¸€äººç§°ï¼ˆç§ï¼‰çš„æ²»æ„ˆç³»æ—¥è¯­æ‘˜è¦ã€‚ã€‚
    ## è¦æ±‚ï¼š
    1. åŒ…å«å¯¹è¯ä¸­çš„æ ¸å¿ƒäº‹ä»¶å’Œå­¦åˆ°çš„ 2-3 ä¸ªæ—¥è¯­è¡¨è¾¾ã€‚
    2. æƒ…æ„ŸçœŸæŒšï¼Œ150å­—å·¦å³ã€‚
    ## æ ¼å¼ï¼šå¿…é¡»è¿”å› JSON {{"title": "...", "diary_ja": "...", "diary_zh": "..."}}
    """
    
    try:
        # 1. è®¾å®šâ€œå¤§è„‘â€çš„å·¥ä½œæ¨¡å¼ã€‚
        model = genai.GenerativeModel(
            model_name=GEMINI_MODEL_ID,
            system_instruction=system_prompt
        )
        
        # 2. æä¾›â€œé£Ÿæâ€,ç®€åŒ–å†å²è®°å½•ï¼Œåªä¿ç•™æ–‡æœ¬è¯­ä¹‰
        history_summary = ""
        for m in request.history:
            role_name = "user" if m.role == "user" else "model"
            history_summary += f"{role_name}: {m.content}\n"

        # 3. ä¸‹è¾¾â€œå¼€å·¥â€æŒ‡ä»¤,ç”Ÿæˆå†…å®¹;è§„å®šâ€œåŒ…è£…æ ¼å¼â€
        response = model.generate_content(
            f"ä»¥ä¸‹æ˜¯å¯¹è¯å†å²ï¼š\n{history_summary}",
            generation_config={"response_mime_type": "application/json"} # å¼ºåˆ¶è¿”å›jsonçš„æ„æ€
        )
        
        # 4. æœ€åâ€œæ‹†ç®±â€å–è´§ã€‚AI è¿”å›çš„æ˜¯ä¸€ä¸²æ­»æ¿çš„â€œå­—ç¬¦ä¸²â€ï¼Œè¿™è¡Œä»£ç æŠŠå®ƒå˜æˆäº† Python èƒ½æ“ä½œçš„â€œå­—å…¸â€ã€‚
        return json.loads(response.text)
    
    except Exception as e:
        print(f"âŒ æ€»ç»“å¤±è´¥: {e}")
        return {"title": "ä»Šæ—¥ã€å›éŸ¿", "diary_ja": "fail", "diary_zh": 'fail'}

# ===========================
# 2.2 æ—¥è®°ä¿®æ”¹æ¥å£ï¼ˆrefined summaryï¼‰
# ===========================

@app.post("/api/refine_summary")
async def refine_summary(request: RefineRequest):
    """
    æ¥æ”¶ç”¨æˆ·ä¿®æ­£æ„è§ï¼Œç”Ÿæˆæœ€ç»ˆçš„ refined_summary
    """
    system_prompt = f"""
    ä½ æ˜¯ä¸€ä½ç²¾é€šæ—¥è¯­æ‰‹å¸çš„èµ„æ·±å¯¼å¸ˆã€‚
    ä»»åŠ¡ï¼šç»“åˆâ€œåŸå§‹å¯¹è¯å†å²â€å’Œâ€œç”¨æˆ·çš„è¡¥å……ä¿®æ­£â€ï¼Œç”Ÿæˆæœ€ç»ˆç‰ˆçš„æ²»æ„ˆç³»æ—¥è®°æ‘˜è¦ã€‚
    è¦æ±‚ï¼š
    1. å¿…é¡»ä¼˜å…ˆå°Šé‡ç”¨æˆ·åœ¨ [ç”¨æˆ·ä¿®æ­£å»ºè®®] ä¸­æåˆ°çš„å†…å®¹ã€‚
    2. æ¶¦è‰²è¯­è¨€ï¼Œä½¿å…¶æ—¥è¯­è¡¨è¾¾æ›´åŠ åœ°é“ã€æ¸©é¦¨ã€‚
    3. ä¿æŒç¬¬ä¸€äººç§°â€œç§â€ã€‚
    æ ¼å¼ï¼šJSON {{"refined_summary_ja": "...", "refined_summary_zh": "..."}}
    """
    try:
        model = genai.GenerativeModel(model_name=GEMINI_MODEL_ID, system_instruction=system_prompt)
        history_text = "\n".join([f"{m.role}: {m.content}" for m in request.history])
        
        input_content = f"""
        [åŸå§‹å¯¹è¯å†å²]:
        {history_text}
        
        [ç”¨æˆ·ä¿®æ­£å»ºè®®]:
        {request.correction_summary}
        """
        
        response = model.generate_content(
            input_content,
            generation_config={"response_mime_type": "application/json"}
        )
        return json.loads(response.text)
    except Exception as e:
        print(f"âŒ ä¿®æ­£æ€»ç»“å¤±è´¥: {e}")
        return {"refined_summary_ja": "Error", "refined_summary_zh": "Error"}

# ===========================
# 3.  æ’­å®¢è„šæœ¬æ¥å£ + æ—¥è®°
# ===========================

@app.post("/api/generate_podcast_and_diary")
async def generate_podcast_and_diary(request: FinalGenerationRequest):
    """
    è¾“å…¥ï¼šcommunication_raw + refined_summary_ja
    è¾“å‡ºï¼šåŒ…å« script, diary, JSON
    """
    # 1. ç²¾ç®€åçš„ç³»ç»ŸæŒ‡ä»¤
    system_prompt = f"""
    ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ’­å®¢ç¼–å‰§å’Œæ‰‹å¸ä½œå®¶,ä¸éœ€è¦å¤ªå¤šå¤§é“ç†ï¼Œå°±æ˜¯ç®€å•ä¸€ç‚¹ï¼Œæ­£èƒ½é‡ä¸€ç‚¹å°±å¥½äº†ã€‚
    ä»»åŠ¡ï¼šåŸºäºå¯¹è¯å†å²å’Œç”¨æˆ·æ€»ç»“çš„æ—¥è®°æ‘˜è¦ï¼Œåˆ›ä½œä¸€æ®µæ—¥è¯­æ’­å®¢è„šæœ¬å’Œä¸€ç¯‡æ²»æ„ˆç³»æ—¥è®°ã€‚
    
    ## ä»»åŠ¡ Aï¼šæ’­å®¢è„šæœ¬ (script)
    - è§’è‰²ï¼šä¸»æŒäºº {request.mentorRole}ï¼ˆå¼•å¯¼è€…ï¼‰ï¼›å˜‰å®¾ï¼šç”¨æˆ·ã€‚
    - è¦æ±‚ï¼šå£è¯­åŒ–ï¼ˆå«ãˆãˆã¨ã€ãªã‚‹ã»ã©ï¼‰ï¼Œçº¦ 6 è½®å¯¹è¯ï¼Œç©¿æ’ 1-2 ä¸ªæ—¥è¯­çŸ¥è¯†ç‚¹ã€‚
    - æ³¨æ„ï¼šå¯ä»¥å‚è€ƒç”¨æˆ·æä¾›çš„æ—¥è®°æ‘˜è¦ï¼Œä½†è¦ä»¥å¯¹è¯å†å²ä¸ºä¸»ã€‚

    ## ä»»åŠ¡ Bï¼šæ²»æ„ˆç³»æ—¥è®° (diary)
    - è§†è§’ï¼šç”¨æˆ·ç¬¬ä¸€äººç§°ã€Œç§ã€ã€‚
    - è¦æ±‚ï¼šåŸºäºç”¨æˆ·æä¾›çš„æ—¥è®°æ‘˜è¦ï¼ˆrefined_summaryï¼‰ï¼Œåˆ›ä½œä¸€ç¯‡æ²»æ„ˆç³»æ—¥è®°ï¼Œçº¦ 100 å­—ï¼Œè¯­æ°”æ¸©æš–ã€‚
    - æ³¨æ„ï¼šæ—¥è®°å†…å®¹åº”è¯¥ä¸ç”¨æˆ·æä¾›çš„æ‘˜è¦ä¿æŒä¸€è‡´ï¼Œä½†å¯ä»¥é€‚å½“æ¶¦è‰²ã€‚

    ## æ ¼å¼è¦æ±‚ (JSON ONLY)ï¼š
    {{
      "script": [
        {{"speaker": "{request.mentorRole}", "content": "..."}},
        {{"speaker": "ç”¨æˆ·", "content": "..."}}
      ],
      "diary": {{
        "title": "ä»Šæ—¥çš„é¢˜ç›®",
        "content_ja": "å†…å®¹"
      }}
    }}
    """
    
    try:
        # 1. å°† communication_raw å’Œ refined_summary_ja ç»„åˆæˆ history
        history = request.to_history()
        
        if not history:
            raise ValueError("ç¼ºå°‘å¯¹è¯ç´ æ (History is empty)")
        
        print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šç»„åˆåçš„ history é•¿åº¦: {len(history)}")
        print(f"   åŒ…å« communication_raw: {len(request.communication_raw)} æ¡")
        print(f"   refined_summary_ja: {request.refined_summary_ja[:50] if request.refined_summary_ja else 'N/A'}...")
        
        # 2. è°ƒç”¨ Gemini ç”Ÿæˆå†…å®¹
        model = genai.GenerativeModel(model_name=GEMINI_MODEL_ID, system_instruction=system_prompt)
        
        # æ„å»ºè¾“å…¥æ–‡æœ¬ï¼šåŒ…å«å¯¹è¯å†å²å’Œç”¨æˆ·æ€»ç»“çš„æ‘˜è¦
        history_text = "\n".join([f"{m.role}: {m.content}" for m in history])
        
        # æ·»åŠ  refined_summary ä½œä¸ºé¢å¤–çš„ä¸Šä¸‹æ–‡
        input_text = f"""ä»¥ä¸‹æ˜¯å®Œæ•´çš„å¯¹è¯ç´ æï¼š
{history_text}

[ç”¨æˆ·æ€»ç»“çš„æ—¥è®°æ‘˜è¦]ï¼š
{request.refined_summary_ja}
"""
        response = model.generate_content(
            input_text,
            generation_config={"response_mime_type": "application/json"}
        )
        
        # 2. è§£æ JSON ç»“æœ
        res_data = json.loads(response.text)
        
        # 3. è¿”å›è„šæœ¬å’Œæ—¥è®°ï¼ˆä¸åŒ…å«éŸ³é¢‘ï¼‰
        result = {
            "script": res_data.get("script", []),
            "diary": res_data.get("diary", {"title": "fail", "content_ja": "fail"}),
            "status": "SUCCESS"
        }
        
        print(f"âœ… æ’­å®¢è„šæœ¬å’Œæ—¥è®°ç”ŸæˆæˆåŠŸ")
        print(f"   æ—¥è®°æ ‡é¢˜: {result['diary'].get('title', 'N/A')}")
        
        return result

    except Exception as e:
        print(f"âŒ fail: {e}")
        import traceback
        traceback.print_exc()
        return {
            "script": [],
            "diary": {"title": "fail", "content_ja": "fail"},
            "status": "ERROR"
        }
    
    # å‰ç«¯è¾“å‡ºç”¨è°ƒç”¨ï¼š
    # è·å–å¯¹è¯æ•°ç»„ï¼šres.script
    # è·å–ç¬¬ä¸€å¥çš„å†…å®¹ï¼šres.script[0].content
    # è·å–ç¬¬ä¸€å¥çš„è§’è‰²ï¼šres.script[0].speaker





# ===========================
# 4.  æ’­å®¢éŸ³é¢‘ç”Ÿæˆæ¥å£
# ===========================
class PodcastScriptRequest(BaseModel):
    script: list  # [{"speaker": "...", "content": "..."}]

class ImageFromPromptsRequest(BaseModel):
    scene_prompts: list[str]  # åœºæ™¯æç¤ºè¯åˆ—è¡¨

class ImageGenerationRequest(BaseModel):
    context: str = ""
    tone: Literal["Gentle", "Normal", "Serious"]
    mentorRole: str = ""
    turn: int = 6
    history: list[Message]
    scene_prompts: list[str] = None  # å¯é€‰çš„åœºæ™¯æç¤ºè¯ï¼Œå¦‚æœæä¾›åˆ™è·³è¿‡æå–æ­¥éª¤

@app.post("/api/generate_podcast_audio")
async def generate_podcast_audio(request: PodcastScriptRequest):
    """
    è¾“å…¥ï¼šæ’­å®¢è„šæœ¬æ•°ç»„ [{'speaker': '...', 'content': '...'}]
    è¾“å‡ºï¼šæ‹¼æ¥åçš„å®Œæ•´ MP3 Base64
    """
    try:
        script = request.script
        
        if not script or not isinstance(script, list):
            return {"error": "è„šæœ¬å†…å®¹ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯", "audio_base64": None, "status": "ERROR"}

        if tts_client is None:
            return {"error": "TTS å®¢æˆ·ç«¯æœªåˆå§‹åŒ–", "audio_base64": None, "status": "ERROR"}

        combined_audio_content = b"" # ç”¨äºå­˜å‚¨æ‹¼æ¥çš„äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®

        print(f"ğŸ”Š å¼€å§‹ç”Ÿæˆå¤šè§’è‰²æ’­å®¢éŸ³é¢‘ï¼Œæ€»è½®æ¬¡: {len(script)}")

        for i, line in enumerate(script, 1):
            speaker = line.get("speaker", "")
            content = line.get("content", "")
            
            # --- æ ¸å¿ƒï¼šéŸ³è‰²åˆ†é…é€»è¾‘ ---
            # å¦‚æœè¯´è¯äººæ˜¯ç”¨æˆ·ï¼ˆå«æœ‰â€œç”¨æˆ·â€æˆ–â€œå˜‰å®¾â€å­—æ ·ï¼‰ï¼Œç”¨éŸ³è‰² C
            # å¦‚æœè¯´è¯äººæ˜¯å¯¼å¸ˆè§’è‰²ï¼Œç”¨éŸ³è‰² B
            if "ç”¨æˆ·" in speaker or "å˜‰å®¾" in speaker or "ç§" in speaker:
                current_speaker_type = "user" # ja-JP-Neural2-C
            else:
                current_speaker_type = "model" # ja-JP-Neural2-B
            
            # è°ƒç”¨å·²æœ‰çš„åˆæˆå‡½æ•°ï¼ˆæ³¨æ„ï¼šéœ€è¦ç¡®ä¿ synthesize_speech è¿”å›çš„æ˜¯åŸå§‹äºŒè¿›åˆ¶æ•°æ®æˆ–åœ¨ä¹‹åè§£ç ï¼‰
            # ä¸ºäº†æ–¹ä¾¿æ‹¼æ¥äºŒè¿›åˆ¶æ•°æ®ï¼Œæˆ‘ä»¬ç¨å¾®è°ƒæ•´é€»è¾‘è·å– response.audio_content
            
            # --- æ¨¡æ‹Ÿåˆæˆè¿‡ç¨‹ ---
            # è¿™é‡Œè°ƒç”¨ Google TTS API å¹¶è·å– audio_content
            # æ³¨æ„ï¼šåˆæˆåå°†äºŒè¿›åˆ¶å†…å®¹è¿½åŠ åˆ° combined_audio_content
            # ä¸»æŒäººï¼ˆå¯¼å¸ˆï¼‰ï¼šä½¿ç”¨ç”·å£° ja-JP-Neural2-B (ç”·å£°)
            # ç”¨æˆ·ï¼ˆå˜‰å®¾ï¼‰ï¼šä½¿ç”¨å¥³å£° ja-JP-Neural2-C (å¥³å£°)
            # æ£€æŸ¥è¯´è¯äººæ˜¯å¦ä¸ºç”¨æˆ·/å˜‰å®¾ï¼ˆæ”¯æŒä¸­æ–‡å’Œæ—¥æ–‡ï¼‰
            if ("ç”¨æˆ·" in speaker or "ãƒ¦ãƒ¼ã‚¶ãƒ¼" in speaker or "å˜‰å®¾" in speaker or "ç§" in speaker or 
                speaker.lower() == "user" or "guest" in speaker.lower()):
                # ç”¨æˆ·/å˜‰å®¾ä½¿ç”¨å¥³å£°
                voice_name = "ja-JP-Neural2-C"  # å¥³å£°
                speaker_gender = "å¥³å£°"
            else:
                # ä¸»æŒäºº/å¯¼å¸ˆä½¿ç”¨ç”·å£°
                voice_name = "ja-JP-Neural2-B"  # ç”·å£°
                speaker_gender = "ç”·å£°"
            
            print(f"  [{i}/{len(script)}] {speaker}: {content[:50]}... ({speaker_gender}: {voice_name})")
            
            synthesis_input = texttospeech.SynthesisInput(text=content)
            voice = texttospeech.VoiceSelectionParams(language_code="ja-JP", name=voice_name)
            audio_config = texttospeech.AudioConfig(
                audio_encoding=texttospeech.AudioEncoding.MP3,
                pitch=0.0,
                speaking_rate=1.0
            )
            
            response = tts_client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)
            combined_audio_content += response.audio_content

        # å°†æœ€ç»ˆæ‹¼æ¥å¥½çš„äºŒè¿›åˆ¶æ•°æ®è½¬ä¸º Base64
        final_base64 = base64.b64encode(combined_audio_content).decode("utf-8")
        print(f"âœ… å¤šè§’è‰²æ’­å®¢åˆæˆæˆåŠŸï¼Œæœ€ç»ˆå¤§å°: {len(final_base64)} å­—ç¬¦")
        
        return {
            "status": "SUCCESS",
            "audio_base64": final_base64,
            "total_lines": len(script)
        }

    except Exception as e:
        print(f"âŒ æ’­å®¢åˆæˆå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return {"error": str(e), "audio_base64": None, "status": "ERROR"}

# ===========================
# 5.  è¯­éŸ³åˆæˆæ¥å£ 
# ===========================
# FastAPI è·¯ç”±ï¼šå¯¹å¤–æä¾› TTS æ¥å£
@app.post("/api/tts")
async def text_to_speech(text: str, speaker: str = "model"):
    """
    TTS è·¯ç”±æ¥å£ï¼Œæ¥æ”¶ HTTP è¯·æ±‚å¹¶è°ƒç”¨ synthesize_speech
    """
    return await synthesize_speech(text=text, speaker=speaker)

# ===========================
# 6. æ¼«ç”»ç”Ÿæˆæ¥å£ 
# ===========================
@app.post("/api/extract_scene_prompts")
async def extract_scene_prompts(request: ChatRequest):
    """
    åªæå–åœºæ™¯æç¤ºè¯ï¼Œä¸ç”Ÿæˆå›¾ç‰‡
    """
    try:
        print(f"ğŸ“ æ”¶åˆ°åœºæ™¯æç¤ºè¯æå–è¯·æ±‚")
        
        # 1. åˆå§‹åŒ–æ–‡æœ¬æ¨¡å‹ï¼Œç”¨äºä»å¯¹è¯å†å²ä¸­æå–"è§†è§‰ç¬é—´"
        text_model = genai.GenerativeModel(GEMINI_MODEL_ID)
        
        # å°†å†å²è®°å½•è½¬åŒ–ä¸ºæ–‡æœ¬ç´ æ
        history_text = "\n".join([f"{m.role}: {m.content}" for m in request.history])
        
        # æç¤ºè¯å·¥ç¨‹ï¼šåŸºäºè„šæœ¬å†…å®¹æå–ä¸¤ä¸ªä¸åŒçš„è§†è§‰ç¬é—´
        extraction_prompt = f"""
        ä½ æ˜¯ä¸€ä½è§†è§‰åœºæ™¯è®¾è®¡å¸ˆã€‚åŸºäºä»¥ä¸‹æ’­å®¢è„šæœ¬å¯¹è¯å†…å®¹ï¼Œæå–ä¸¤ä¸ªå®Œå…¨ä¸åŒã€æœ‰å¼ºçƒˆå¯¹æ¯”çš„è§†è§‰ç¬é—´ã€‚
        
        ## æ ¸å¿ƒè¦æ±‚ï¼š
        1. **å¿…é¡»ä¸¥æ ¼åŸºäºå¯¹è¯å†…å®¹**ï¼šåœºæ™¯å¿…é¡»ç›´æ¥å¯¹åº”å¯¹è¯ä¸­æåˆ°çš„å…·ä½“ç‰©å“ã€åœ°ç‚¹ã€åŠ¨ä½œæˆ–æƒ…å¢ƒ
        2. **åœºæ™¯1**ï¼šä»å¯¹è¯çš„å‰åŠéƒ¨åˆ†æå–ç¬¬ä¸€ä¸ªå…³é”®è§†è§‰å…ƒç´ ï¼ˆç‰¹å†™è§†è§’ï¼‰
        3. **åœºæ™¯2**ï¼šä»å¯¹è¯çš„ååŠéƒ¨åˆ†æå–ç¬¬äºŒä¸ªä¸åŒçš„å…³é”®è§†è§‰å…ƒç´ ï¼ˆç‰¹å†™è§†è§’ï¼‰
        4. **ä¸¤ä¸ªåœºæ™¯å¿…é¡»å®Œå…¨ä¸åŒ**ï¼šä¸åŒçš„ç‰©å“ã€ä¸åŒçš„åœ°ç‚¹ã€ä¸åŒçš„åŠ¨ä½œæˆ–ä¸åŒçš„æƒ…ç»ªçŠ¶æ€
        5. **é¿å…è™šæ„**ï¼šä¸è¦æ·»åŠ å¯¹è¯ä¸­æ²¡æœ‰æåˆ°çš„ç‰©å“æˆ–åœºæ™¯
        6. **æç¤ºè¯å­—æ•°**ï¼šå¤§çº¦300å­—å·¦å³
        
        ## é£æ ¼è¦æ±‚ï¼ˆåœ¨æè¿°ä¸­ä½“ç°ï¼‰ï¼š
        - æ‰‹ç»˜é£æ ¼ï¼Œå¯çˆ±çš„æŸ”å’Œçš„ç®€ç¬”ç”»é£æ ¼
        - æŸ”å’Œçš„æ°´å½©è´¨æ„Ÿ
        - æ¸©æš–ã€æŸ”å’Œçš„å…‰çº¿
        - æ°›å›´æ ¹æ®åœºæ™¯å†…å®¹è€Œå®š
        
        ## åœºæ™¯è¦æ±‚ï¼š
        - ä¸­ç­‰åœºæ™¯ï¼Œä¸éœ€è¦å¤ªå…·ä½“
        - æ¯ä¸ªåœºæ™¯è¦æœ‰æ˜ç¡®çš„è§†è§‰ç„¦ç‚¹
        - ä¸¤ä¸ªåœºæ™¯çš„æ„å›¾ã€ç‰©å“ã€åŠ¨ä½œéƒ½è¦æœ‰æ˜æ˜¾åŒºåˆ«
        
        ## æ’­å®¢è„šæœ¬å¯¹è¯å†…å®¹ï¼š
        {history_text}
        
        ## è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼è¿”å› JSONï¼‰ï¼š
        {{
          "scene_prompts": [
            "ç¬¬ä¸€ä¸ªåœºæ™¯ï¼š[åŸºäºå¯¹è¯å†…å®¹çš„å…·ä½“æè¿°ï¼Œå¿…é¡»åŒ…å«å¯¹è¯ä¸­æåˆ°çš„ç‰©å“ã€åœ°ç‚¹æˆ–åŠ¨ä½œï¼Œ300å­—ä»¥å†…]",
            "ç¬¬äºŒä¸ªåœºæ™¯ï¼š[åŸºäºå¯¹è¯å†…å®¹çš„å…·ä½“æè¿°ï¼Œå¿…é¡»ä¸ç¬¬ä¸€ä¸ªå®Œå…¨ä¸åŒï¼Œå¿…é¡»åŒ…å«å¯¹è¯ä¸­æåˆ°çš„ç‰©å“ã€åœ°ç‚¹æˆ–åŠ¨ä½œï¼Œ300å­—ä»¥å†…]"
          ]
        }}
        
        ## é‡è¦æç¤ºï¼š
        1. æç¤ºè¯å¿…é¡»ä½¿ç”¨ä¸­æ–‡æè¿°
        2. åœºæ™¯æè¿°å¿…é¡»ç›´æ¥å¯¹åº”å¯¹è¯ä¸­æåˆ°çš„å†…å®¹ï¼Œä¸è¦è™šæ„
        3. å¦‚æœå¯¹è¯ä¸­æåˆ°"åº—"ã€"ã‚¢ãƒ«ãƒã‚¤ãƒˆ"ã€"ä»•äº‹"ç­‰ï¼Œåœºæ™¯åº”è¯¥åæ˜ è¿™äº›å†…å®¹
        4. å¦‚æœå¯¹è¯ä¸­æåˆ°"å‰²ã‚Šåˆ‡ã‚‹"ã€"å‚™ãˆ"ç­‰æ¦‚å¿µï¼Œå¯ä»¥é€šè¿‡ç›¸å…³çš„ç‰©å“æˆ–åŠ¨ä½œæ¥ä½“ç°
        5. ç¡®ä¿ä¸¤ä¸ªåœºæ™¯æœ‰æ˜æ˜¾çš„åŒºåˆ«ï¼Œä¸è¦ä½¿ç”¨ç›¸ä¼¼çš„ç‰©å“ã€åŠ¨ä½œæˆ–æ„å›¾
        """
        
        # è·å–åœºæ™¯æè¿°
        print(f"ğŸ“ æ­£åœ¨æå–åœºæ™¯æç¤ºè¯...")
        extract_res = text_model.generate_content(
            extraction_prompt, 
            generation_config={"response_mime_type": "application/json"}
        )
        print(f"âœ… åœºæ™¯æç¤ºè¯æå–æˆåŠŸ")
        
        try:
            prompts_raw = json.loads(extract_res.text).get("scene_prompts", [])
            # æ¸…ç†æç¤ºè¯ï¼šç§»é™¤ "ç¬¬ä¸€ä¸ªåœºæ™¯ï¼š" å’Œ "ç¬¬äºŒä¸ªåœºæ™¯ï¼š" ç­‰å‰ç¼€
            prompts = []
            for prompt in prompts_raw:
                # ç§»é™¤ä¸­æ–‡å‰ç¼€ï¼ˆå¦‚ "ç¬¬ä¸€ä¸ªåœºæ™¯ï¼š"ã€"ç¬¬äºŒä¸ªåœºæ™¯ï¼š"ã€"åœºæ™¯1ï¼š"ç­‰ï¼‰
                cleaned = prompt
                if "ï¼š" in prompt:
                    cleaned = prompt.split("ï¼š", 1)[1].strip()
                elif ":" in prompt:
                    cleaned = prompt.split(":", 1)[1].strip()
                prompts.append(cleaned)
            
            print(f"   æå–åˆ° {len(prompts)} ä¸ªåœºæ™¯æç¤ºè¯")
            print(f"\nğŸ“ åœºæ™¯æç¤ºè¯è¯¦æƒ…:")
            for i, prompt in enumerate(prompts, 1):
                print(f"   åœºæ™¯ {i}: {prompt}")
            
            return {
                "status": "SUCCESS",
                "scene_prompts": prompts
            }
        except json.JSONDecodeError as json_err:
            print(f"âŒ JSON è§£æå¤±è´¥: {json_err}")
            print(f"   å“åº”æ–‡æœ¬: {extract_res.text[:500]}")
            return {
                "status": "ERROR",
                "scene_prompts": [],
                "error": f"åœºæ™¯æç¤ºè¯è§£æå¤±è´¥: {str(json_err)}"
            }
            
    except Exception as e:
        print(f"âŒ åœºæ™¯æç¤ºè¯æå–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {
            "status": "ERROR",
            "scene_prompts": [],
            "error": str(e)
        }

@app.post("/api/generate_image_from_prompts")
async def generate_image_from_prompts(request: ImageFromPromptsRequest):
    """
    ä½¿ç”¨å·²æå–çš„åœºæ™¯æç¤ºè¯ç”Ÿæˆå›¾ç‰‡
    """
    try:
        prompts = request.scene_prompts
        print(f"ğŸ¨ æ”¶åˆ°å›¾ç‰‡ç”Ÿæˆè¯·æ±‚ï¼ˆä½¿ç”¨æä¾›çš„æç¤ºè¯ï¼‰")
        print(f"   æç¤ºè¯æ•°é‡: {len(prompts)}")
        for i, prompt in enumerate(prompts, 1):
            print(f"   åœºæ™¯ {i}: {prompt}")
        
        if not prompts:
            return {
                "status": "ERROR",
                "scenes": [],
                "error": "æç¤ºè¯åˆ—è¡¨ä¸ºç©º"
            }

        # è°ƒç”¨ nano-banana-pro-preview ç”Ÿæˆå›¾ç‰‡
        image_gen_model = genai.GenerativeModel("nano-banana-pro-preview")
        
        generated_scenes = []
        
        for i, p in enumerate(prompts[:2]):  # ç¡®ä¿åªå–å‰ä¸¤ä¸ª
            print(f"\nğŸ¨ æ­£åœ¨ç”Ÿæˆåœºæ™¯ {i+1}/2")
            print(f"   å®Œæ•´æç¤ºè¯: {p}")
            
            try:
                # è°ƒç”¨ Nano Banana çš„å›¾åƒç”Ÿæˆæ¥å£
                response = image_gen_model.generate_content(p)
                
                # æå–å›¾ç‰‡æ•°æ®
                if response.candidates and len(response.candidates) > 0:
                    candidate = response.candidates[0]
                    if candidate.content and candidate.content.parts:
                        for part in candidate.content.parts:
                            if hasattr(part, 'inline_data') and part.inline_data:
                                img_data_bytes = part.inline_data.data
                                # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸º base64 å­—ç¬¦ä¸²
                                img_data_base64 = base64.b64encode(img_data_bytes).decode("utf-8")
                                
                                generated_scenes.append({
                                    "scene_id": i + 1,
                                    "image_base64": img_data_base64,
                                    "description": p
                                })
                                print(f"âœ… åœºæ™¯ {i+1} ç”ŸæˆæˆåŠŸ")
                                break
                        else:
                            # å¦‚æœæ²¡æœ‰æ‰¾åˆ° inline_dataï¼Œå°è¯•å…¶ä»–æ–¹å¼
                            print(f"âš ï¸ åœºæ™¯ {i+1} æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ")
                            generated_scenes.append({
                                "scene_id": i + 1,
                                "image_url": "https://images.unsplash.com/photo-1464822759023-fed622ff2c3b",
                                "description": p,
                                "error": "æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®"
                            })
                    else:
                        print(f"âš ï¸ åœºæ™¯ {i+1} å“åº”æ ¼å¼å¼‚å¸¸")
                        generated_scenes.append({
                            "scene_id": i + 1,
                            "image_url": "https://images.unsplash.com/photo-1464822759023-fed622ff2c3b",
                            "description": p,
                            "error": "å“åº”æ ¼å¼å¼‚å¸¸"
                        })
                else:
                    print(f"âš ï¸ åœºæ™¯ {i+1} æ— å€™é€‰ç»“æœ")
                    generated_scenes.append({
                        "scene_id": i + 1,
                        "image_url": "https://images.unsplash.com/photo-1464822759023-fed622ff2c3b",
                        "description": p,
                        "error": "æ— å€™é€‰ç»“æœ"
                    })
                    
            except Exception as img_err:
                print(f"âŒ åœºæ™¯ {i+1} ç”Ÿæˆå¤±è´¥: {img_err}")
                import traceback
                traceback.print_exc()
                # å•å¼ ç”Ÿæˆå¤±è´¥çš„å¤‡é€‰é€»è¾‘
                generated_scenes.append({
                    "scene_id": i + 1,
                    "image_url": "https://images.unsplash.com/photo-1464822759023-fed622ff2c3b",
                    "description": p,
                    "error": str(img_err)
                })

        return {
            "status": "SUCCESS",
            "scenes": generated_scenes
        }

    except Exception as e:
        print(f"âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {
            "status": "ERROR",
            "scenes": [],
            "error": str(e)
        }

@app.post("/api/generate_image")
async def generate_image(request: ChatRequest):
    """
    åŸºäºæ’­å®¢è„šæœ¬å†…å®¹ï¼Œåˆ©ç”¨ Nano Banana ç”Ÿæˆä¸¤å¹…å‰åœåŠ›é£æ ¼çš„åœºæ™¯æ¼«ç”»
    å…ˆæå–æç¤ºè¯ï¼Œå†ç”Ÿæˆå›¾ç‰‡ï¼ˆå®Œæ•´æµç¨‹ï¼‰
    """
    try:
        print(f"ğŸ¨ æ”¶åˆ°å›¾ç‰‡ç”Ÿæˆè¯·æ±‚ï¼ˆå®Œæ•´æµç¨‹ï¼‰")
        
        # å…ˆæå–æç¤ºè¯
        text_model = genai.GenerativeModel(GEMINI_MODEL_ID)
        
        # å°†å†å²è®°å½•è½¬åŒ–ä¸ºæ–‡æœ¬ç´ æ
        history_text = "\n".join([f"{m.role}: {m.content}" for m in request.history])
        
        # æç¤ºè¯å·¥ç¨‹ï¼šåŸºäºè„šæœ¬å†…å®¹æå–ä¸¤ä¸ªä¸åŒçš„è§†è§‰ç¬é—´
        extraction_prompt = f"""
        ä½ æ˜¯ä¸€ä½è§†è§‰åœºæ™¯è®¾è®¡å¸ˆã€‚åŸºäºä»¥ä¸‹æ’­å®¢è„šæœ¬å¯¹è¯å†…å®¹ï¼Œæå–ä¸¤ä¸ªå®Œå…¨ä¸åŒã€æœ‰å¼ºçƒˆå¯¹æ¯”çš„è§†è§‰ç¬é—´ã€‚
        
        ## æ ¸å¿ƒè¦æ±‚ï¼š
        1. **å¿…é¡»ä¸¥æ ¼åŸºäºå¯¹è¯å†…å®¹**ï¼šåœºæ™¯å¿…é¡»ç›´æ¥å¯¹åº”å¯¹è¯ä¸­æåˆ°çš„å…·ä½“ç‰©å“ã€åœ°ç‚¹ã€åŠ¨ä½œæˆ–æƒ…å¢ƒ
        2. **åœºæ™¯1**ï¼šä»å¯¹è¯çš„å‰åŠéƒ¨åˆ†æå–ç¬¬ä¸€ä¸ªå…³é”®è§†è§‰å…ƒç´ 
        3. **åœºæ™¯2**ï¼šä»å¯¹è¯çš„ååŠéƒ¨åˆ†æå–ç¬¬äºŒä¸ªä¸åŒçš„å…³é”®è§†è§‰å…ƒç´ 
        4. **ä¸¤ä¸ªåœºæ™¯å¿…é¡»å®Œå…¨ä¸åŒ**ï¼šä¸åŒçš„ç‰©å“ã€ä¸åŒçš„åœ°ç‚¹ã€ä¸åŒçš„åŠ¨ä½œæˆ–ä¸åŒçš„æƒ…ç»ªçŠ¶æ€
        5. **é¿å…è™šæ„**ï¼šä¸è¦æ·»åŠ å¯¹è¯ä¸­æ²¡æœ‰æåˆ°çš„ç‰©å“æˆ–åœºæ™¯
        6. æç¤ºè¯å¤§æ¦‚300å­—å·¦å³
        
        ## é£æ ¼è¦æ±‚ï¼ˆåœ¨æè¿°ä¸­ä½“ç°ï¼‰ï¼š
        - æŸ”å’Œçš„æ°´å½©è´¨æ„Ÿ
        - æ¸©æš–ã€æŸ”å’Œçš„å…‰çº¿
        - æ¸©é¦¨èˆ’é€‚çš„æ°›å›´
        - ç®€ç¬”ç”»é£æ ¼
        - å‰åœåŠ›æ¼«ç”»é£æ ¼
        
        ## åœºæ™¯è¦æ±‚ï¼š
        - é¿å…ç‰¹åˆ«å°çš„åœºæ™¯
        - æ¯ä¸ªåœºæ™¯è¦æœ‰æ˜ç¡®çš„è§†è§‰ç„¦ç‚¹
        - ä¸¤ä¸ªåœºæ™¯çš„æ„å›¾ã€ç‰©å“ã€åŠ¨ä½œéƒ½è¦æœ‰æ˜æ˜¾åŒºåˆ«
        
        ## æ’­å®¢è„šæœ¬å¯¹è¯å†…å®¹ï¼š
        {history_text}
        
        ## è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼è¿”å› JSONï¼‰ï¼š
        {{
          "scene_prompts": [
            "ç¬¬ä¸€ä¸ªåœºæ™¯ï¼š[åŸºäºå¯¹è¯å†…å®¹çš„å…·ä½“æè¿°ï¼Œå¿…é¡»åŒ…å«å¯¹è¯ä¸­æåˆ°çš„ç‰©å“ã€åœ°ç‚¹æˆ–åŠ¨ä½œï¼Œ300å­—ä»¥å†…]",
            "ç¬¬äºŒä¸ªåœºæ™¯ï¼š[åŸºäºå¯¹è¯å†…å®¹çš„å…·ä½“æè¿°ï¼Œå¿…é¡»ä¸ç¬¬ä¸€ä¸ªå®Œå…¨ä¸åŒï¼Œå¿…é¡»åŒ…å«å¯¹è¯ä¸­æåˆ°çš„ç‰©å“ã€åœ°ç‚¹æˆ–åŠ¨ä½œï¼Œ300å­—ä»¥å†…]"
          ]
        }}
        
        ## é‡è¦æç¤ºï¼š
        1. æç¤ºè¯å¿…é¡»ä½¿ç”¨ä¸­æ–‡æè¿°
        2. åœºæ™¯æè¿°å¿…é¡»ç›´æ¥å¯¹åº”å¯¹è¯ä¸­æåˆ°çš„å†…å®¹ï¼Œä¸è¦è™šæ„
        3. å¦‚æœå¯¹è¯ä¸­æåˆ°"åº—"ã€"ã‚¢ãƒ«ãƒã‚¤ãƒˆ"ã€"ä»•äº‹"ç­‰ï¼Œåœºæ™¯åº”è¯¥åæ˜ è¿™äº›å†…å®¹
        4. å¦‚æœå¯¹è¯ä¸­æåˆ°"å‰²ã‚Šåˆ‡ã‚‹"ã€"å‚™ãˆ"ç­‰æ¦‚å¿µï¼Œå¯ä»¥é€šè¿‡ç›¸å…³çš„ç‰©å“æˆ–åŠ¨ä½œæ¥ä½“ç°ã€‚
        5. ç¡®ä¿ä¸¤ä¸ªåœºæ™¯æœ‰æ˜æ˜¾çš„åŒºåˆ«ï¼Œä¸è¦ä½¿ç”¨ç›¸ä¼¼çš„ç‰©å“ã€åŠ¨ä½œæˆ–æ„å›¾
        """
        
        # è·å–åœºæ™¯æè¿°
        print(f"ğŸ“ æ­£åœ¨æå–åœºæ™¯æç¤ºè¯...")
        extract_res = text_model.generate_content(
            extraction_prompt, 
            generation_config={"response_mime_type": "application/json"}
        )
        print(f"âœ… åœºæ™¯æç¤ºè¯æå–æˆåŠŸ")
        
        try:
            prompts_raw = json.loads(extract_res.text).get("scene_prompts", [])
            # æ¸…ç†æç¤ºè¯ï¼šç§»é™¤ "ç¬¬ä¸€ä¸ªåœºæ™¯ï¼š" å’Œ "ç¬¬äºŒä¸ªåœºæ™¯ï¼š" ç­‰å‰ç¼€
            prompts = []
            for prompt in prompts_raw:
                # ç§»é™¤ä¸­æ–‡å‰ç¼€ï¼ˆå¦‚ "ç¬¬ä¸€ä¸ªåœºæ™¯ï¼š"ã€"ç¬¬äºŒä¸ªåœºæ™¯ï¼š"ã€"åœºæ™¯1ï¼š"ç­‰ï¼‰
                cleaned = prompt
                if "ï¼š" in prompt:
                    cleaned = prompt.split("ï¼š", 1)[1].strip()
                elif ":" in prompt:
                    cleaned = prompt.split(":", 1)[1].strip()
                prompts.append(cleaned)
            
            print(f"   æå–åˆ° {len(prompts)} ä¸ªåœºæ™¯æç¤ºè¯")
            print(f"\nğŸ“ åœºæ™¯æç¤ºè¯è¯¦æƒ…:")
            for i, prompt in enumerate(prompts, 1):
                print(f"   åœºæ™¯ {i}: {prompt}")
        except json.JSONDecodeError as json_err:
            print(f"âŒ JSON è§£æå¤±è´¥: {json_err}")
            print(f"   å“åº”æ–‡æœ¬: {extract_res.text[:500]}")
            return {
                "status": "ERROR",
                "scenes": [],
                "error": f"åœºæ™¯æç¤ºè¯è§£æå¤±è´¥: {str(json_err)}"
            }
        
        if not prompts:
            print("âš ï¸ è­¦å‘Šï¼šæœªè·å–åˆ°åœºæ™¯æç¤ºè¯")
            return {
                "status": "ERROR",
                "scenes": [],
                "error": "æœªè·å–åˆ°åœºæ™¯æç¤ºè¯"
            }
        
        # è°ƒç”¨ç”Ÿæˆå›¾ç‰‡çš„é€»è¾‘ï¼ˆå¤ç”¨ä¸Šé¢çš„ä»£ç ï¼‰
        image_gen_model = genai.GenerativeModel("nano-banana-pro-preview")
        
        generated_scenes = []
        
        for i, p in enumerate(prompts[:2]):  # ç¡®ä¿åªå–å‰ä¸¤ä¸ª
            print(f"\nğŸ¨ æ­£åœ¨ç”Ÿæˆåœºæ™¯ {i+1}/2")
            print(f"   å®Œæ•´æç¤ºè¯: {p}")
            
            try:
                # è°ƒç”¨ Nano Banana çš„å›¾åƒç”Ÿæˆæ¥å£
                response = image_gen_model.generate_content(p)
                
                # æå–å›¾ç‰‡æ•°æ®
                if response.candidates and len(response.candidates) > 0:
                    candidate = response.candidates[0]
                    if candidate.content and candidate.content.parts:
                        for part in candidate.content.parts:
                            if hasattr(part, 'inline_data') and part.inline_data:
                                img_data_bytes = part.inline_data.data
                                # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸º base64 å­—ç¬¦ä¸²
                                img_data_base64 = base64.b64encode(img_data_bytes).decode("utf-8")
                                
                                generated_scenes.append({
                                    "scene_id": i + 1,
                                    "image_base64": img_data_base64,
                                    "description": p
                                })
                                print(f"âœ… åœºæ™¯ {i+1} ç”ŸæˆæˆåŠŸ")
                                break
                        else:
                            # å¦‚æœæ²¡æœ‰æ‰¾åˆ° inline_dataï¼Œå°è¯•å…¶ä»–æ–¹å¼
                            print(f"âš ï¸ åœºæ™¯ {i+1} æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ")
                            generated_scenes.append({
                                "scene_id": i + 1,
                                "image_url": "https://images.unsplash.com/photo-1464822759023-fed622ff2c3b",
                                "description": p,
                                "error": "æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®"
                            })
                    else:
                        print(f"âš ï¸ åœºæ™¯ {i+1} å“åº”æ ¼å¼å¼‚å¸¸")
                        generated_scenes.append({
                            "scene_id": i + 1,
                            "image_url": "https://images.unsplash.com/photo-1464822759023-fed622ff2c3b",
                            "description": p,
                            "error": "å“åº”æ ¼å¼å¼‚å¸¸"
                        })
                else:
                    print(f"âš ï¸ åœºæ™¯ {i+1} æ— å€™é€‰ç»“æœ")
                    generated_scenes.append({
                        "scene_id": i + 1,
                        "image_url": "https://images.unsplash.com/photo-1464822759023-fed622ff2c3b",
                        "description": p,
                        "error": "æ— å€™é€‰ç»“æœ"
                    })
                    
            except Exception as img_err:
                print(f"âŒ åœºæ™¯ {i+1} ç”Ÿæˆå¤±è´¥: {img_err}")
                import traceback
                traceback.print_exc()
                # å•å¼ ç”Ÿæˆå¤±è´¥çš„å¤‡é€‰é€»è¾‘
                generated_scenes.append({
                    "scene_id": i + 1,
                    "image_url": "https://images.unsplash.com/photo-1464822759023-fed622ff2c3b",
                    "description": p,
                    "error": str(img_err)
                })

        return {
            "status": "SUCCESS",
            "scenes": generated_scenes
        }

    except Exception as e:
        print(f"âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {
            "status": "ERROR",
            "scenes": [],
            "error": str(e)
        }




class AvatarRequest(BaseModel):
    role: str  # è§’è‰²åç§°

class DetectRolesRequest(BaseModel):
    text: str  # ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬

@app.post("/api/detect_roles")
async def detect_roles(request: DetectRolesRequest):
    """
    ä»ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ä¸­è¯†åˆ«äººç‰©è§’è‰²
    ä½¿ç”¨ Gemini æ¨¡å‹åˆ†ææ–‡æœ¬ï¼Œæå–æåˆ°çš„äººç‰©
    """
    try:
        text = request.text
        print(f"ğŸ” æ”¶åˆ°äººç‰©è¯†åˆ«è¯·æ±‚")
        
        if not text or text.strip() == '':
            return {
                "status": "SUCCESS",
                "roles": []
            }
        
        # ä½¿ç”¨ Gemini æ¨¡å‹è¯†åˆ«äººç‰©
        text_model = genai.GenerativeModel(GEMINI_MODEL_ID)
        
        prompt = f"""è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­è¯†åˆ«å‡ºæ‰€æœ‰æåˆ°çš„äººç‰©è§’è‰²ã€‚åªè¿”å›äººç‰©åç§°ï¼Œä¸è¦è¿”å›ç”¨æˆ·æœ¬äººã€‚

è¦æ±‚ï¼š
1. åªæå–æ˜ç¡®æåˆ°çš„äººç‰©åç§°ï¼ˆå¦‚ï¼šå¼ ä¸‰ã€æå››ã€è€å¸ˆã€æœ‹å‹ã€åŒäº‹ç­‰ï¼‰
2. ä¸è¦åŒ…å«ç”¨æˆ·æœ¬äººï¼ˆå¦‚ï¼šæˆ‘ã€è‡ªå·±ç­‰ï¼‰
3. å¦‚æœæåˆ°çš„æ˜¯èŒä¸šæˆ–å…³ç³»ï¼ˆå¦‚ï¼šè€å¸ˆã€æœ‹å‹ï¼‰ï¼Œè¯·ä¿ç•™
4. è¿”å›æ ¼å¼ä¸ºJSONæ•°ç»„ï¼Œä¾‹å¦‚ï¼š["å¼ ä¸‰", "æå››", "è€å¸ˆ"]
5. å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°äººç‰©ï¼Œè¿”å›ç©ºæ•°ç»„ï¼š[]

æ–‡æœ¬å†…å®¹ï¼š
{text}

è¯·ç›´æ¥è¿”å›JSONæ•°ç»„ï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜æ–‡å­—ã€‚"""
        
        response = text_model.generate_content(prompt)
        
        # è§£æå“åº”
        response_text = response.text.strip()
        # å°è¯•æå–JSONæ•°ç»„
        import re
        json_match = re.search(r'\[.*?\]', response_text, re.DOTALL)
        if json_match:
            import json
            roles = json.loads(json_match.group())
            print(f"âœ… è¯†åˆ«åˆ° {len(roles)} ä¸ªäººç‰©: {roles}")
            return {
                "status": "SUCCESS",
                "roles": roles if isinstance(roles, list) else []
            }
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œå°è¯•æŒ‰è¡Œåˆ†å‰²
            lines = [line.strip() for line in response_text.split('\n') if line.strip()]
            roles = [line for line in lines if not line.startswith('#') and not line.startswith('//')]
            print(f"âœ… è¯†åˆ«åˆ° {len(roles)} ä¸ªäººç‰©: {roles}")
            return {
                "status": "SUCCESS",
                "roles": roles[:10]  # æœ€å¤šè¿”å›10ä¸ª
            }
        
    except Exception as e:
        print(f"âŒ äººç‰©è¯†åˆ«å¼‚å¸¸: {str(e)}")
        return {
            "status": "ERROR",
            "roles": [],
            "error": str(e)
        }

@app.post("/api/generate_avatar")
async def generate_avatar(request: AvatarRequest):
    """
    æ ¹æ®è§’è‰²åç§°ç”ŸæˆAIå¤´åƒ
    ä½¿ç”¨ nano-banana-pro-preview ç”Ÿæˆè§’è‰²å¤´åƒ
    """
    try:
        role_name = request.role
        print(f"ğŸ¨ æ”¶åˆ°å¤´åƒç”Ÿæˆè¯·æ±‚: {role_name}")
        
        if not role_name or role_name.strip() == '':
            return {
                "status": "ERROR",
                "error": "è§’è‰²åç§°ä¸èƒ½ä¸ºç©º"
            }
        
        # æ„å»ºå¤´åƒç”Ÿæˆæç¤ºè¯ - æ ¹æ®è§’è‰²åç”Ÿæˆå·®å¼‚åŒ–çš„å¤´åƒ
        # é€šè¿‡è§’è‰²åæ¨æ–­å¤–è§‚ç‰¹å¾ï¼Œç¡®ä¿ä¸åŒè§’è‰²æœ‰ä¸åŒå¤–è§‚
        prompt = f"""Generate a unique anime-style avatar portrait. The character is named "{role_name}" (a Japanese person).
        
        IMPORTANT: The character's appearance must be UNIQUE and reflect their name/personality:
        - If the name suggests a senior/older person (å…ˆè¼©, å…ˆç”Ÿ, éƒ¨é•·): mature face, professional look
        - If the name suggests a friend/peer (å‹äºº, ã¡ã‚ƒã‚“, ãã‚“): young, casual, friendly
        - If the name suggests authority (åº—é•·, ç¤¾é•·, æ•™æˆ): confident, dignified expression
        - Each different name MUST produce a visually DIFFERENT character
        
        Character name for reference: "{role_name}"
        
        Style requirements:
        - Clean anime/manga style portrait
        - Head and shoulders only, centered
        - Distinct hairstyle and hair color unique to this character
        - Unique eye color and facial features
        - Simple solid color background (NOT white - use a soft pastel color)
        - 512x512 pixels, high quality
        - The character should look like a real person you'd meet in Japan"""
        
        # è°ƒç”¨ nano-banana-pro-preview ç”Ÿæˆå¤´åƒ
        image_gen_model = genai.GenerativeModel("nano-banana-pro-preview")
        
        print(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆå¤´åƒ: {role_name}")
        response = image_gen_model.generate_content(prompt)
        
        # æå–å›¾ç‰‡æ•°æ®
        if response.candidates and len(response.candidates) > 0:
            candidate = response.candidates[0]
            if candidate.content and candidate.content.parts:
                for part in candidate.content.parts:
                    if hasattr(part, 'inline_data') and part.inline_data:
                        img_data_bytes = part.inline_data.data
                        # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸º base64 å­—ç¬¦ä¸²
                        img_data_base64 = base64.b64encode(img_data_bytes).decode("utf-8")
                        
                        print(f"âœ… å¤´åƒç”ŸæˆæˆåŠŸ: {role_name}")
                        return {
                            "status": "SUCCESS",
                            "image_base64": img_data_base64,
                            "role": role_name
                        }
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ•°æ®ï¼Œè¿”å›é”™è¯¯
        print(f"âš ï¸ å¤´åƒç”Ÿæˆå¤±è´¥: æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®")
        return {
            "status": "ERROR",
            "error": "æœªèƒ½ç”Ÿæˆå¤´åƒå›¾ç‰‡"
        }
        
    except Exception as e:
        print(f"âŒ å¤´åƒç”Ÿæˆå¼‚å¸¸: {str(e)}")
        return {
            "status": "ERROR",
            "error": str(e)
        }

class TranscribeRequest(BaseModel):
    audio_base64: str
    audio_mime_type: str = "audio/webm"

@app.post("/api/transcribe")
async def transcribe_audio(request: TranscribeRequest):
    """
    è¯­éŸ³è½¬å†™ç«¯ç‚¹ï¼šå°†ç”¨æˆ·å½•åˆ¶çš„éŸ³é¢‘è½¬å†™ä¸ºæ–‡å­—
    æ”¯æŒä¸­æ–‡ã€æ—¥è¯­ã€è‹±è¯­åŠå¤šè¯­è¨€æ··åˆ
    """
    try:
        print(f"ğŸ¤ æ”¶åˆ°è¯­éŸ³è½¬å†™è¯·æ±‚ï¼ŒéŸ³é¢‘å¤§å°={len(request.audio_base64)} å­—ç¬¦, mime={request.audio_mime_type}")
        if not request.audio_base64:
            return {"status": "ERROR", "error": "æœªæä¾›éŸ³é¢‘æ•°æ®", "text": ""}
        
        text_model = genai.GenerativeModel(GEMINI_MODEL_ID)
        
        # å°† base64 è§£ç ä¸º bytesï¼Œä½¿ç”¨ Gemini SDK çš„ Part æ ¼å¼
        audio_bytes = base64.b64decode(request.audio_base64)
        audio_part = genai.protos.Part(
            inline_data=genai.protos.Blob(
                mime_type=request.audio_mime_type,
                data=audio_bytes
            )
        )
        
        prompt = """è¯·ä»”ç»†å¬è¿™æ®µè¯­éŸ³ï¼Œå¹¶å°†å…¶è½¬å†™ä¸ºæ–‡å­—ã€‚
è¦æ±‚ï¼š
1. ç”¨æˆ·å¯èƒ½è¯´çš„æ˜¯ä¸­æ–‡ã€æ—¥è¯­ã€è‹±è¯­æˆ–å¤šè¯­è¨€æ··åˆï¼Œè¯·å¦‚å®è½¬å†™
2. ä¿ç•™ç”¨æˆ·çš„åŸå§‹è¡¨è¾¾ï¼ŒåŒ…æ‹¬å£è¯­åŒ–çš„è¡¨è¾¾ã€åœé¡¿è¯ç­‰
3. å¦‚æœå¬ä¸æ¸…æŸäº›éƒ¨åˆ†ï¼Œå°½é‡æ¨æµ‹å¹¶è½¬å†™
4. åªè¿”å›è½¬å†™åçš„çº¯æ–‡å­—ï¼Œä¸è¦æ·»åŠ ä»»ä½•è¯´æ˜æˆ–æ ‡ç‚¹ç¬¦å·è§£é‡Š
5. å¦‚æœå®Œå…¨å¬ä¸åˆ°å£°éŸ³æˆ–æ— æ³•è¯†åˆ«ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²"""
        
        response = text_model.generate_content([audio_part, prompt])
        transcribed_text = response.text.strip()
        print(f"âœ… è¯­éŸ³è½¬å†™æˆåŠŸ: {transcribed_text[:100]}...")
        return {"status": "SUCCESS", "text": transcribed_text}
    except Exception as e:
        print(f"âŒ è¯­éŸ³è½¬å†™å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {"status": "ERROR", "error": str(e), "text": ""}

if __name__ == "__main__":
    import uvicorn
    # ç›‘å¬ 127.0.0.1 ç¡®ä¿æœ¬åœ°é€šä¿¡ç¨³å®š
    uvicorn.run(app, host="127.0.0.1", port=8000)


